{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: AstropyDeprecationWarning: astropy.extern.six will be removed in 4.0, use the six module directly if it is still needed [astropy.extern.six]\n",
      "WARNING: nan_treatment='interpolate', however, NaN values detected post convolution. A contiguous region of NaN values, larger than the kernel size, are present in the input array. Increase the kernel size to avoid this. [astropy.convolution.convolve]\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Adam2\\Anaconda\\envs\\mypython3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3334: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "print(python_version())\n",
    "\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "#importing libraries\n",
    "from astropy.io import fits\n",
    "from astropy.convolution import convolve, Gaussian2DKernel\n",
    "from astropy.wcs import WCS\n",
    "from reproject import reproject_exact  #a package that can be added to astropy using anaconda or pip (see their docs pg)\n",
    "from reproject import reproject_interp\n",
    "\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "# #finding the path to every fits images in a directory\n",
    "def im_name_finder(path, file_type):\n",
    "    #Using glob (it's a unix command similar to ls)\n",
    "    #WARNING: using recursive=True...depending how many images you use this could be very slow, it's recommended not to have too many subfolders\n",
    "    #if needed, some example code is commented towards the latter half of this code that could help make an alternative\n",
    "    all_names = glob.glob(path, recursive=True)\n",
    "\n",
    "    #IMPORTANT: Using \"fit\" here because it is inclusive of both fits and FIT...some files end in \"FIT\" and need to be included\n",
    "    #using s.lower() include uppercase names\n",
    "    im_names = [s for s in all_names if 'fit' in s.lower()]\n",
    "\n",
    "    return im_names\n",
    "\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "'''now convolve my image with a PSF of the image we're projecting ONTO\n",
    "an approx PSF can be found by assuming a 2D Gaussian func with a width (a FWHM) of the diffrac limit\n",
    "that is the st dev of the Gaussian is about the st dev is about = lambda/D\n",
    "a list of PSFs are found on https://docs.astropy.org/en/stable/convolution/kernels.html\n",
    "\n",
    "Notes:\n",
    "FIRST: always must convert hdu1_pixtorad to radians! It's inconsistent otherwise, and lambda/D is generally in radians\n",
    "\n",
    "what we're using for the gaussian width is the FWHM, not the radius of the first ring of the diffraction pattern,\n",
    "so it's 1.2 not 1.22 times lambda/D\n",
    "\n",
    "D is 85 cm for spitzer\n",
    "D is 2.4 m for hubble\n",
    "'''\n",
    "\n",
    "def im_conv(low_res_name, D, hdu1_pix_torad, hdu2_dat):\n",
    "    #unfortuantely no good way to find wavelength from header right now. can enter it manually, but I tried to automate it\n",
    "\n",
    "    #reading in excel file of wavelengths...right now needs to be in same directory as this code\n",
    "    #first col is a substring of the fits image file name, the second col is the wavelengths in microns\n",
    "    df = pd.read_excel('../../imglams.xlsx')\n",
    "    cols = df.columns\n",
    "    cols_str = [str(i) for i in df[cols[0]]]\n",
    "    #some test cases I was using\n",
    "    #print(low_res_name)\n",
    "    #print(cols_str)\n",
    "    #print([i in low_res_name for i in cols_str])\n",
    "    #print(np.where([i in low_res_name for i in cols_str]))\n",
    "    #sys.exit()\n",
    "\n",
    "    #this finds the loc in the excel file where the image substring matches our image name\n",
    "    #it then finds the wavelength value corresponding to that loc\n",
    "    lam =  df.loc[np.where([i in low_res_name for i in cols_str])[0][0]].values[1] #lambda in microns\n",
    "\n",
    "    #finding angular resolution...the FWHM of our Gaussian PSF\n",
    "    res = 1.2 * lam / D         #resolution in radians\n",
    "    res = res / hdu1_pix_torad        #so converting to pixels\n",
    "\n",
    "    #finding PSF and then calculating the convolution of our image and the PSF of the image we're projecting onto\n",
    "    gauss_kernel = Gaussian2DKernel(res)\n",
    "    hdu_conv = convolve(hdu2_dat, gauss_kernel)\n",
    "\n",
    "    return hdu_conv\n",
    "\n",
    "\n",
    "# In[27]:\n",
    "\n",
    "#setting up a new fits file to be saved and viewed in DS9\n",
    "#primarily to save the image we reprojected, but can also be used to save the convolved images\n",
    "def fits_saver(array, wcs_header, name, save_path):\n",
    "    '''\n",
    "    array is a 2d array of data - could be from reprojecting one image onto another or from convolution\n",
    "    wcs_header is a header containing the wcs coords of the image that we projected onto or of the orig image (if from the convolution)\n",
    "    name is the path to some image you're using. It will get string split at the / character, and the func only takes the last element of that splitting\n",
    "    save_path is the folder you want to save to...recommended to also add something to the start of the images names to make it clear what you did to them (e.g. 'Regridded/regrid_')\n",
    "    '''\n",
    "\n",
    "    #creating a new file and adding the reprojected array of data as well as the WCS that we projected onto\n",
    "    hdu_new = fits.PrimaryHDU(array, header=wcs_header)\n",
    "    hdul = fits.HDUList([hdu_new])\n",
    "\n",
    "    #saving the file\n",
    "    new_filename = name.split('/')[-1]  #grabs the file name we were using from before\n",
    "    hdul.writeto(save_path+new_filename, overwrite=True)\n",
    "\n",
    "    return (save_path+new_filename)\n",
    "\n",
    "\n",
    "\n",
    "# In[21]:\n",
    "\n",
    "#EX: grabbing all the fits image paths in a directory, so they can be looped through and their data opened\n",
    "#set your path to some directory with images (the images can be in subdirectories)\n",
    "#using ** will grab all files even in subdirectories...WARNING this will take longer\n",
    "path = '../../../ngc1333_fits/'\n",
    "im_names_hub_dash = im_name_finder(path+'*', 'fit')\n",
    "im_names_hub_dash = [i.replace('\\\\', '/') for i in im_names_hub_dash]\n",
    "im_names_hub = [path+'126_image.fits', path+'128_image.fits', path+'164_image.fits']\n",
    "\n",
    "#The output from im names hub ['../HH12_Hubble/HH6_126.fits', '../HH12_Hubble/128_image.fits', '../HH12_Hubble/126build_shift_2_drz.fits', '../HH12_Hubble/HH6_164.fits', '../HH12_Hubble/126_image.fits', '../HH12_Hubble/164_image.fits', '../HH12_Hubble/164build_shift_2_drz.fits', '../HH12_Hubble/128build_shift_2_drz.fits', '../HH12_Hubble/HH6_128.fits']\n",
    "#or on local it's ['../../../ngc1333_fits/126_image.fits', '../../../ngc1333_fits/128_image.fits', '../../../ngc1333_fits/164_image.fits']\n",
    "#print(im_names_hub_dash)...that's on the ssh computer...\n",
    "#on local machine it's like # ['../../../ngc1333_fits/126build_shift_2_drz.fits', '../../../ngc1333_fits/126_image.fits', \n",
    "# '../../../ngc1333_fits/128build_shift_2_drz.fits', '../../../ngc1333_fits/128_image.fits', \n",
    "# '../../../ngc1333_fits/164build_shift_2_drz.fits', '../../../ngc1333_fits/164_image.fits', \n",
    "# '../../../ngc1333_fits/halph_hart_image.fits', '../../../ngc1333_fits/url_saver.py']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[28]:\n",
    "\n",
    "#Minimal loop through all the images, including a try/except in case an image is faulty for whatever reason\n",
    "#IMPORTANT: A more detailed example between two single images is at the end of this code with many more comments\n",
    "\n",
    "#First, we need to setup the image we're projecting ONTO\n",
    "#This will be the same no matter the loop, so only need to do this once\n",
    "#low_res = [x for x in im_names_spitz if 'n1333_lh_3_SiII_' in x][0]  #finding the lowest res image - LH and long lambda, so [SiII]\n",
    "#hdu1 = fits.open(low_res)[0]\n",
    "low_res = im_names_hub_dash[0]   #Could also let this be a hubble image...if so, see the hubble loop below for how to setup grabbing the data, header, pixel conversion from the hdu\n",
    "hdu1 = fits.open(low_res)\n",
    "\n",
    "#hdu1_pix = hdu1.header['CDELT2'] #the pixel size in degrees, CDELT is the keyword for Spitzer images\n",
    "#hdu1_pix_torad = hdu1_pix * np.pi / 180.\n",
    "hdu1_pix = hdu1[0].header['D001SCAL'] #pixel size in arcsec, but D001SCAL is the keyword for Hubble images\n",
    "hdu1_pix_torad = hdu1_pix / 206265.\n",
    "hdu1_fnu = hdu1[0].header['PHOTFNU']\n",
    "\n",
    "low_res = im_names_hub[0]\n",
    "hdu1 = fits.open(low_res)\n",
    "hdu1_data = hdu1[0].data\n",
    "hdu1_header = hdu1[0].header\n",
    "\n",
    "\n",
    "for name, name2 in [(im_names_hub[2],im_names_hub_dash[2]), (im_names_hub[1],im_names_hub_dash[4]), (im_names_hub_dash[6],im_names_hub_dash[6])]:\n",
    "    hdu2 = fits.open(name2)\n",
    "#     try:\n",
    "    #reading in data\n",
    "    hdu2_pix = hdu2[0].header['D001SCAL'] #same as above line, but D001SCAL is the keyword for Hubble images\n",
    "    hdu2_pix_torad = hdu2_pix / 206265.\n",
    "    \n",
    "    \n",
    "    if name != '../../../ngc1333_fits/halph_hart_image.fits':\n",
    "        hdu2_fnu = hdu2[0].header['PHOTFNU']\n",
    "        hdu2 = fits.open(name)\n",
    "        \n",
    "        hdu2_data = hdu2[0].data\n",
    "        hdu2_header = hdu2[0].header\n",
    "    else:\n",
    "        hdu2 = fits.open(name)\n",
    "        hdu2_fnu = hdu2[1].header['PHOTFNU']\n",
    "        \n",
    "        hdu2_data = hdu2[1].data\n",
    "        hdu2_header = hdu2[1].header\n",
    "        \n",
    "\n",
    "    #convolving images\n",
    "    D = 2.4 #that of Hubble, in m\n",
    "    D *= 1e6 #converting to microns since x m / 1 m * 1E6 microns gets microns, the unit of our wavelength file\n",
    "\n",
    "    hdu1_conv = im_conv(name, D, hdu2_pix_torad, hdu1_data)\n",
    "    hdu2_conv = im_conv(low_res, D, hdu1_pix_torad, hdu2_data)\n",
    "\n",
    "    #converting the convolved image to correct units and saving it so we can reproject it\n",
    "    #conversion needed for hubble case since units are not in terms of surface brightness\n",
    "    hdu1_conv_scaled = hdu1_conv\n",
    "    hdu1_conv_scaled = hdu1_conv_scaled * hdu1_fnu / 1e6 #converting to MJy\n",
    "    hdu1_conv_scaled = hdu1_conv_scaled / hdu1_pix**2. #* 4.25e10 #dividing out sr, D001SCAL is key for pixel size in arcsec\n",
    "\n",
    "    hdu2_conv_scaled = hdu2_conv\n",
    "    hdu2_conv_scaled = hdu2_conv_scaled * hdu2_fnu / 1e6 #converting to MJy\n",
    "    hdu2_conv_scaled = hdu2_conv_scaled / hdu2_pix**2. #* 4.25e10 #dividing out sr, D001SCAL is key for pixel size in arcsec\n",
    "\n",
    "\n",
    "    #you'll need to set the WCS to be that of the header you're basing this off of...ie the header\n",
    "    w = WCS(hdu2_header)\n",
    "    wcs_header = w.to_header()\n",
    "    file_start = '../../Convolved_Images_Hub/conv_unitsfix2_'\n",
    "    conv2_path = fits_saver(hdu2_conv_scaled, wcs_header, name, file_start)\n",
    "\n",
    "\n",
    "    w = WCS(hdu1_header)\n",
    "    wcs_header = w.to_header()\n",
    "    file_start = '../../Convolved_Images_Hub/conv_unitsfix2_'\n",
    "    conv1_path = fits_saver(hdu1_conv_scaled, wcs_header, low_res, file_start)\n",
    "\n",
    "\n",
    "    #reprojection of one hdu using the header (coords and pixels) of another\n",
    "    #The first input is the path to the file we're reprojecting. The second input is the header of the image we're projecting ONTO\n",
    "    #para is False for large images (like these hubble ones)\n",
    "    #output is array (a 2D array of data) and footprint (the footprint from the analysis)\n",
    "    para = False\n",
    "    array, footprint = reproject_exact(conv2_path, w, shape_out=hdu1_conv_scaled.shape, parallel=para)\n",
    "\n",
    "    #now that we have a reprojected hubble image for hdu2 and both are convolved, need to\n",
    "    #divide one by the other...then can use the same wcs header that we projected onto (hdu1's)!\n",
    "    #data_ratio = np.divide(array, hdu1_conv_scaled, out=np.zeros_like(array), where=hdu1_conv_scaled!=0) #need to do np.divide to guarantee we get no divide by zero issue...\n",
    "\n",
    "\n",
    "    #saving a new fits file from the reprojected image\n",
    "    #first, grabbing the WCS coords of the appropriate image to be set as the header of the new image\n",
    "    # remember to have the right header with the wcs below and that it matches the one we're projecting ONTO\n",
    "    #w = WCS(hdu1_header)\n",
    "    #wcs_header = w.to_header()\n",
    "    #save_path = 'Regridded_Hub/regrid_'  #See fits_saver's \"save_path\" description for explanation\n",
    "    #fits_saver(data_ratio, wcs_header, 'hub_fe_ratio.fits', save_path)  #saving the reprojected image\n",
    "    \n",
    "    w = WCS(hdu1_header)\n",
    "    wcs_header = w.to_header()\n",
    "    file_start = '../../Regridded_Hub/regrid_unitsfix2_'\n",
    "    regrid_2_path = fits_saver(array, wcs_header, name, file_start)\n",
    "    regrid_2_foot_path = fits_saver(footprint, wcs_header, name, file_start+'footprint_unitsfix2_')\n",
    "\n",
    "#     except Exception as e: print(e, name)\n",
    "\n",
    "sys.exit()\n",
    "\n",
    "                                                                                                                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from astropy.nddata import Cutout2D\n",
    "from astropy import coordinates\n",
    "from astropy import units as u\n",
    "\n",
    "def imcrop(mylon, mylat, xsize, ysize, im, w):\n",
    "    # example coordinate - you'll have to figure one out that's in your map\n",
    "    center = coordinates.SkyCoord(mylon*u.deg, mylat*u.deg, frame='fk5')\n",
    "\n",
    "    # then make an array cutout\n",
    "    co = nddata.Cutout2D(im, center, size=[ysize, xsize]*u.deg, wcs=w)\n",
    "\n",
    "    return co.data, co.wcs#making cutout of image...based on https://stackoverflow.com/questions/33512681/splicing-image-array-fits-file-using-coordinates-from-header\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def implot(data, w, wcscond):\n",
    "    fig = plt.figure()\n",
    "    \n",
    "    if  wcscond == True:\n",
    "        fig.add_subplot(111, projection=w)\n",
    "    else:\n",
    "        fig.add_subplot(111)\n",
    "    plt.imshow(data, origin='lower', cmap=plt.cm.viridis, vmin =0, vmax=1)\n",
    "    plt.xlabel('RA')\n",
    "    plt.ylabel('Dec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#only saving the fits files\n",
    "\n",
    "import glob\n",
    "filenames = glob.glob('../../../ngc1333_fits/*image.fits')\n",
    "print(filenames)\n",
    "\n",
    "#handling image ^@^@^@^@data\n",
    "import sys\n",
    "import numpy as np\n",
    "from astropy.io import fits\n",
    "from astropy import wcs\n",
    "from astropy.nddata import Cutout2D\n",
    "\n",
    "\n",
    "for file in filenames:\n",
    "    hdu1 = fits.open(file)  #import image\n",
    "    w = wcs.WCS(hdu1[1].header)   #get wcs coords\n",
    "#     print(w.array_shape)\n",
    "#     w = wcs.utils.wcs_to_celestial_frame(w)\n",
    "    \n",
    "    #following idea about slices from https://joseph-long.com/writing/from-sky-coordinates-to-pixels-and-back/\n",
    "    ymin_int = 2750\n",
    "    ymax_int = 3000\n",
    "    xmin_int = 4550\n",
    "    xmax_int = 4900\n",
    "    slices = (slice(ymin_int, ymax_int), slice(xmin_int, xmax_int))\n",
    "    \n",
    "        #implementing slices method...doesn't seem to work for wcs\n",
    "    #     data = hdu1[1].data[1000:4000, 1000:7000]    #grab data\n",
    "#     data = hdu1[1].data[ymin_int:ymax_int, xmin_int:xmax_int]    #grab data    \n",
    "#     data = hdu1[1].data[slices]\n",
    "#     new_wcs = w.slice(slices)\n",
    "    \n",
    "    #cuting out data and wcs\n",
    "    data = hdu1[1].data\n",
    "    \n",
    "    position = (4725, 2875)  #x, y!\n",
    "#     position = wcs.utils.pixel_to_skycoord(position[0], position[1], w) #converting to sky coords!\n",
    "    size = (240, 300)  #y, x!...necessary b/c of how cutout works\n",
    "#     sizexy = wcs.utils.pixel_to_skycoord(size[1], size[0], w)\n",
    "#     print(sizexy)\n",
    "#     size= [sizexy[1], sizexy[0]]\n",
    "    \n",
    "    cutout = Cutout2D(data, position, size, wcs = w.celestial)\n",
    "    datacut = cutout.data\n",
    "    wcscut = cutout.wcs \n",
    "#     print(wcscut.is_celestial)\n",
    "    \n",
    "    #updating header with WCS info\n",
    "    newhead = hdu1[0].header.update(wcscut.to_header())\n",
    "    hdu1.close()\n",
    "\n",
    "    #plotting\n",
    "    implot(datacut, wcscut)  \n",
    "#     implot(data, new_wcs)     #plot\n",
    "#     plt.savefig('datacut.png')\n",
    "#     sys.exit()\n",
    "\n",
    "    \n",
    "    #saving full fits file...\n",
    "    lamnum = file[file.index('build')-3:file.index('build')]\n",
    "    fits.writeto('HH6_'+lamnum+\".fits\", datacut, wcscut.to_header(), overwrite=True)\n",
    "#     fits.writeto('HH6_'+lamnum+\".fits\", datacut, newhead, overwrite=True)\n",
    "\n",
    "#     output_hdul = new_wcs.to_fits()\n",
    "#     output_hdul[0].data = data\n",
    "#     output_hdul.writeto('HH6_'+file[:3]+\".fits\", overwrite=True)\n",
    "#     sys.exit()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
