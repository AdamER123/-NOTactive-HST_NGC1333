{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8.5\n"
     ]
    }
   ],
   "source": [
    "#From https://photutils.readthedocs.io/en/stable/epsf.html\n",
    "\n",
    "#purpose is to take HST images, identify, and get resolution from point sources (stars)\n",
    "\n",
    "import astropy.units as u\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astroquery.simbad import Simbad\n",
    "\n",
    "#just to check python version - should be 3.7.4\n",
    "from platform import python_version\n",
    "print(python_version())\n",
    "\n",
    "#importing libraries\n",
    "from astropy.io import fits\n",
    "from astropy.convolution import convolve, Gaussian2DKernel, Box2DKernel\n",
    "from astropy.nddata import Cutout2D\n",
    "from astropy.wcs import WCS\n",
    "\n",
    "import glob\n",
    "import itertools\n",
    "import matplotlib \n",
    "# matplotlib.use('Agg') #invokved b/c just plain matplotlib was insufficient\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['03h29m02.8902198504s' '+31d16m00.953186124s']\n",
      " ['03h29m02.1578803464s' '+31d16m11.433429732s']\n",
      " ['3h29m03.7578170808s' '+31d16m03.947525688s']]\n",
      "[<Table length=1>\n",
      "MAIN_ID       RA           DEC      ...     COO_BIBCODE     SCRIPT_NUMBER_ID\n",
      "           \"h:m:s\"       \"d:m:s\"    ...                                     \n",
      " object     str13         str13     ...        object            int32      \n",
      "------- ------------- ------------- ... ------------------- ----------------\n",
      "ASR   2 03 29 02.8902 +31 16 00.953 ... 2020yCat.1350....0G                1, <Table length=1>\n",
      "MAIN_ID       RA           DEC      ...     COO_BIBCODE     SCRIPT_NUMBER_ID\n",
      "           \"h:m:s\"       \"d:m:s\"    ...                                     \n",
      " object     str13         str13     ...        object            int32      \n",
      "------- ------------- ------------- ... ------------------- ----------------\n",
      "ASR   3 03 29 02.1578 +31 16 11.433 ... 2020yCat.1350....0G                1]\n"
     ]
    }
   ],
   "source": [
    "#the goal of this cell is to refine object coordinates from some initial guesses using either 2MASS or GAIA\n",
    "\n",
    "#taking star coords from text file\n",
    "star_coords = np.genfromtxt('hh711_star_coords.txt', dtype=str)\n",
    "print(star_coords)\n",
    "\n",
    "#setting up query\n",
    "result_table = []\n",
    "for i in star_coords[:-1]:\n",
    "    ra, dec = i\n",
    "    result_table.append(Simbad.query_region(SkyCoord(ra+dec, frame='icrs'), radius='0.05s'))\n",
    "print(result_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['conv_checks/epsffwhm_conv_656shifted_flam_0301_oIreproject2.fits', 'conv_checks/epsffwhm_conv_656shifted_flam_656_hareproject_shifted_up5_left3.fits', 'conv_checks/epsffwhm_conv_656shifted_flam_672_sIIreproject.fits', 'conv_checks/epsffwhm_conv_656shifted_flam_background_corr_126_aligned.fits', 'conv_checks/epsffwhm_conv_656shifted_flam_background_corr_128_aligned.fits', 'conv_checks/epsffwhm_conv_656shifted_flam_background_corr_164_aligned.fits']\n",
      "loaded data!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arubi\\anaconda3\\lib\\site-packages\\astropy\\visualization\\stretch.py:285: RuntimeWarning: invalid value encountered in log\n",
      "  np.log(values, out=values)\n",
      "<ipython-input-3-ffe518f38548>:112: MatplotlibDeprecationWarning: shading='flat' when X and Y have the same dimensions as C is deprecated since 3.3.  Either specify the corners of the quadrilaterals with X and Y, or pass shading='auto', 'nearest' or 'gouraud', or set rcParams['pcolor.shading'].  This will become an error two minor releases later.\n",
      "  axes[1,0].pcolormesh(x, y, epsf.data)\n",
      "<ipython-input-3-ffe518f38548>:112: MatplotlibDeprecationWarning: shading='flat' when X and Y have the same dimensions as C is deprecated since 3.3.  Either specify the corners of the quadrilaterals with X and Y, or pass shading='auto', 'nearest' or 'gouraud', or set rcParams['pcolor.shading'].  This will become an error two minor releases later.\n",
      "  axes[1,0].pcolormesh(x, y, epsf.data)\n",
      "C:\\Users\\arubi\\anaconda3\\lib\\site-packages\\astropy\\visualization\\stretch.py:285: RuntimeWarning: invalid value encountered in log\n",
      "  np.log(values, out=values)\n",
      "<ipython-input-3-ffe518f38548>:112: MatplotlibDeprecationWarning: shading='flat' when X and Y have the same dimensions as C is deprecated since 3.3.  Either specify the corners of the quadrilaterals with X and Y, or pass shading='auto', 'nearest' or 'gouraud', or set rcParams['pcolor.shading'].  This will become an error two minor releases later.\n",
      "  axes[1,0].pcolormesh(x, y, epsf.data)\n",
      "C:\\Users\\arubi\\anaconda3\\lib\\site-packages\\astropy\\visualization\\stretch.py:285: RuntimeWarning: invalid value encountered in log\n",
      "  np.log(values, out=values)\n",
      "<ipython-input-3-ffe518f38548>:112: MatplotlibDeprecationWarning: shading='flat' when X and Y have the same dimensions as C is deprecated since 3.3.  Either specify the corners of the quadrilaterals with X and Y, or pass shading='auto', 'nearest' or 'gouraud', or set rcParams['pcolor.shading'].  This will become an error two minor releases later.\n",
      "  axes[1,0].pcolormesh(x, y, epsf.data)\n",
      "C:\\Users\\arubi\\anaconda3\\lib\\site-packages\\astropy\\visualization\\stretch.py:285: RuntimeWarning: invalid value encountered in log\n",
      "  np.log(values, out=values)\n",
      "<ipython-input-3-ffe518f38548>:112: MatplotlibDeprecationWarning: shading='flat' when X and Y have the same dimensions as C is deprecated since 3.3.  Either specify the corners of the quadrilaterals with X and Y, or pass shading='auto', 'nearest' or 'gouraud', or set rcParams['pcolor.shading'].  This will become an error two minor releases later.\n",
      "  axes[1,0].pcolormesh(x, y, epsf.data)\n",
      "<ipython-input-3-ffe518f38548>:112: MatplotlibDeprecationWarning: shading='flat' when X and Y have the same dimensions as C is deprecated since 3.3.  Either specify the corners of the quadrilaterals with X and Y, or pass shading='auto', 'nearest' or 'gouraud', or set rcParams['pcolor.shading'].  This will become an error two minor releases later.\n",
      "  axes[1,0].pcolormesh(x, y, epsf.data)\n"
     ]
    }
   ],
   "source": [
    "#next, we load in some HST images\n",
    "#the hubble images\n",
    "path = 'conv_checks/epsffwhm_conv_*'\n",
    "files_data = [i.replace('\\\\', '/') for i in glob.glob(path)]\n",
    "print(files_data)\n",
    "\n",
    "#initializing some lists to be used\n",
    "hdu_data_list = []\n",
    "hdu_header_list = []\n",
    "\n",
    "#opening data and headers\n",
    "hdu_list = [fits.open(i) for i in files_data]\n",
    "\n",
    "#I'm using count here just to point to specific indices that I've set up...unfortunately some have different headers...\n",
    "#the only diff between the if and else cases are the indexing of the hdu's, some need 1 and some need 0\n",
    "#I've tried to group it for convience, so the the first two have the same headers, the last 3 have the same headers\n",
    "count = 0\n",
    "for hdu_data in hdu_list:\n",
    "    #reading in data for general use  and header for wcs\n",
    "    #converting by times by flam * bw from e-/sec...should get units of erg/cm^2/sec as above\n",
    "    hdu_data_list.append(hdu_data[0].data)\n",
    "    hdu_header_list.append(hdu_data[0].header)\n",
    "\n",
    "    count += 1\n",
    "\n",
    "print('loaded data!')\n",
    "\n",
    "#finally, make psfs for each star and then we determine the resolution from the PSFs\n",
    "#can be done by fitting a gaussian (or other kernel) and normalizing so integral of psf is 1\n",
    "\n",
    "#follow https://photutils.readthedocs.io/en/stable/epsf.html\n",
    "\n",
    "#now, locate spots on the images\n",
    "from astropy.nddata import NDData\n",
    "from astropy.table import Table\n",
    "from astropy.wcs.utils import skycoord_to_pixel\n",
    "from photutils.psf import extract_stars #use this to make star cutouts\n",
    "\n",
    "# nddata = NDData(data=hdu_data_list[-1], wcs=WCS(hdu_header_list[-1]))   #here reformatting data from 1.64 micron HST image\n",
    "nddata_list = [NDData(data=i, wcs=j) for i,j in zip(hdu_data_list, hdu_header_list) ]\n",
    "\n",
    "#this was made complicated bc you cannot directly go from skycoord to Table\n",
    "stars_list = []\n",
    "for nddata in nddata_list:\n",
    "\n",
    "    stars_tbl = Table(names=('x', 'y'))\n",
    "    for i in range(len(result_table)):\n",
    "        ra_dec_formatted = SkyCoord(result_table[i]['RA'][0] + ' ' + result_table[i]['DEC'][0], frame='icrs', unit=(u.hourangle, u.deg))\n",
    "        pix = skycoord_to_pixel(ra_dec_formatted, WCS(hdu_header_list[i]))\n",
    "        stars_tbl.add_row(pix)\n",
    "\n",
    "    stars = extract_stars(nddata, stars_tbl, size=25) \n",
    "    stars_list.append(stars)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.visualization import simple_norm\n",
    "nrows = 1\n",
    "ncols = 2\n",
    "\n",
    "file_start = ['conv_0301_oIreproject2', 'conv_hareproject_shifted_up5_left3', 'conv_672_sIIreproject', 'conv_126_aligned', 'conv_128_aligned', 'conv_164_aligned.fits', 'f_Fe', 'f_H']\n",
    "\n",
    "for i in range(len(stars_list)):\n",
    "    fig, ax = plt.subplots(nrows=nrows, ncols=ncols, figsize=(15, 15))\n",
    "    ax = ax.ravel()\n",
    "\n",
    "    for j in range(nrows*ncols):\n",
    "        norm = simple_norm(stars_list[i][j], 'log', percent=99.)\n",
    "        ax[j].imshow(stars_list[i][j], norm=norm, origin='lower', cmap='viridis')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('hh7_11_checks/psfcutouts_epsffwhm_conv/'+file_start[i]+'_psfcutout_epsffwhm_conv.png')\n",
    "    plt.close()\n",
    "\n",
    "#attempting and failing to make an effective psf fitter\n",
    "\n",
    "#increase maxiters to smooth more and decrease oversampling to avoid issues \n",
    "from photutils.psf import EPSFBuilder\n",
    "epsf_builder = EPSFBuilder(oversampling=1, maxiters=30,\n",
    "                           progress_bar=False)  \n",
    "\n",
    "for i in range(len(stars_list)):\n",
    "    epsf, fitted_stars = epsf_builder(stars_list[i])  \n",
    "    norm = simple_norm(epsf.data, 'log', percent=99.)\n",
    "    plt.imshow(epsf.data, norm=norm, origin='lower', cmap='viridis')\n",
    "    plt.colorbar()\n",
    "    plt.savefig('hh7_11_checks/EPSFs_epsffwhm_conv/'+file_start[i]+'_EPSF_epsffwhm_conv.png')\n",
    "    plt.close()\n",
    "    \n",
    "        #https://photutils.readthedocs.io/en/stable/psf_matching.html could be inspiration\n",
    "    #https://www.stsci.edu/files/live/sites/www/files/home/hst/instrumentation/wfc3/documentation/instrument-science-reports-isrs/_documents/2016/WFC3-2016-12.pdf can see for more...\n",
    "\n",
    "    #instead let's double check stackoverflow for now...seems complex\n",
    "    #ultimately just trying epsf cross section, like in https://stackoverflow.com/questions/18920614/plot-cross-section-through-heat-map\n",
    "\n",
    "    # Coordinates of the line we'd like to sample along\n",
    "    line = [(0, 13.5), (25, 13.5)]\n",
    "\n",
    "    # Convert the line to pixel/index coordinates\n",
    "    x, y = np.arange(epsf.data.shape[0]), np.arange(epsf.data.shape[1])\n",
    "    x_world, y_world = np.array(list(zip(*line)))\n",
    "    col = epsf.data.shape[1] * (x_world - x.min()) / x.ptp()\n",
    "    row = epsf.data.shape[0] * (y_world - y.min()) / y.ptp()\n",
    "\n",
    "    # Interpolate the line at \"num\" points...\n",
    "    num = 27\n",
    "    row, col = [np.linspace(item[0], item[1], num) for item in [row, col]]\n",
    "\n",
    "    # Plot...\n",
    "    fig, axes = plt.subplots(figsize=(10, 8), nrows=2, ncols=2)\n",
    "    fig.delaxes(axes[0,1])\n",
    "\n",
    "    axes[1,0].pcolormesh(x, y, epsf.data)\n",
    "    axes[1,0].plot(x_world, y_world, 'ro-')\n",
    "    axes[1,0].plot(y_world, x_world, 'bo-')\n",
    "    axes[1,0].axis('image')\n",
    "\n",
    "    # Extract the values along the line, using cubic interpolation\n",
    "    import scipy as sp\n",
    "    #horizontal cut\n",
    "    cross_sec_hori = sp.ndimage.map_coordinates(epsf.data, np.vstack((row, col)))\n",
    "    axes[0,0].scatter(np.arange(len(cross_sec_hori)), cross_sec_hori, color='r')\n",
    "\n",
    "    #vertical cut\n",
    "    cross_sec_vert = sp.ndimage.map_coordinates(epsf.data, np.vstack((col, row)))\n",
    "    axes[1,1].scatter(cross_sec_vert, np.arange(len(cross_sec_vert)), color='b')\n",
    "\n",
    "    plt.savefig('hh7_11_checks/psf_profiles_epsffwhm_conv/'+file_start[i]+'_EPSF_epsffwhm_conv.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#next, we load in some HST images\n",
    "#the hubble images\n",
    "path = 'conv_checks/selfconv_*'\n",
    "files_data = [i.replace('\\\\', '/') for i in glob.glob(path)]\n",
    "print(files_data)\n",
    "\n",
    "#initializing some lists to be used\n",
    "hdu_data_list = []\n",
    "hdu_header_list = []\n",
    "\n",
    "#opening data and headers\n",
    "hdu_list = [fits.open(i) for i in files_data]\n",
    "\n",
    "#I'm using count here just to point to specific indices that I've set up...unfortunately some have different headers...\n",
    "#the only diff between the if and else cases are the indexing of the hdu's, some need 1 and some need 0\n",
    "#I've tried to group it for convience, so the the first two have the same headers, the last 3 have the same headers\n",
    "count = 0\n",
    "for hdu_data in hdu_list:\n",
    "    #reading in data for general use  and header for wcs\n",
    "    #converting by times by flam * bw from e-/sec...should get units of erg/cm^2/sec as above\n",
    "    hdu_data_list.append(hdu_data[0].data)\n",
    "    hdu_header_list.append(hdu_data[0].header)\n",
    "\n",
    "    count += 1\n",
    "\n",
    "print('loaded data!')\n",
    "\n",
    "#finally, make psfs for each star and then we determine the resolution from the PSFs\n",
    "#can be done by fitting a gaussian (or other kernel) and normalizing so integral of psf is 1\n",
    "\n",
    "#follow https://photutils.readthedocs.io/en/stable/epsf.html\n",
    "\n",
    "#now, locate spots on the images\n",
    "from astropy.nddata import NDData\n",
    "from astropy.table import Table\n",
    "from astropy.wcs.utils import skycoord_to_pixel\n",
    "from photutils.psf import extract_stars #use this to make star cutouts\n",
    "\n",
    "# nddata = NDData(data=hdu_data_list[-1], wcs=WCS(hdu_header_list[-1]))   #here reformatting data from 1.64 micron HST image\n",
    "nddata_list = [NDData(data=i, wcs=j) for i,j in zip(hdu_data_list, hdu_header_list) ]\n",
    "\n",
    "#this was made complicated bc you cannot directly go from skycoord to Table\n",
    "stars_list = []\n",
    "for nddata in nddata_list:\n",
    "\n",
    "    stars_tbl = Table(names=('x', 'y'))\n",
    "    for i in range(len(result_table)):\n",
    "        ra_dec_formatted = SkyCoord(result_table[i]['RA'][0] + ' ' + result_table[i]['DEC'][0], frame='icrs', unit=(u.hourangle, u.deg))\n",
    "        pix = skycoord_to_pixel(ra_dec_formatted, WCS(hdu_header_list[i]))\n",
    "        stars_tbl.add_row(pix)\n",
    "\n",
    "    stars = extract_stars(nddata, stars_tbl, size=25) \n",
    "    stars_list.append(stars)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.visualization import simple_norm\n",
    "nrows = 1\n",
    "ncols = 3\n",
    "\n",
    "file_start = ['conv_0301_oIreproject2', 'conv_hareproject_shifted_up5_left3', 'conv_672_sIIreproject', 'conv_126_aligned', 'conv_128_aligned', 'conv_164_aligned.fits', 'f_Fe', 'f_H']\n",
    "\n",
    "for i in range(len(stars_list)):\n",
    "    fig, ax = plt.subplots(nrows=nrows, ncols=ncols, figsize=(15, 15))\n",
    "    ax = ax.ravel()\n",
    "\n",
    "    for j in range(nrows*ncols):\n",
    "        norm = simple_norm(stars_list[i][j], 'log', percent=99.)\n",
    "        ax[j].imshow(stars_list[i][j], norm=norm, origin='lower', cmap='viridis')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('hh7_11_checks/psfcutouts_selfconv/'+file_start[i]+'_psfcutout_selfconv.png')\n",
    "    plt.close()\n",
    "\n",
    "#attempting and failing to make an effective psf fitter\n",
    "\n",
    "#increase maxiters to smooth more and decrease oversampling to avoid issues \n",
    "from photutils.psf import EPSFBuilder\n",
    "epsf_builder = EPSFBuilder(oversampling=1, maxiters=30,\n",
    "                           progress_bar=False)  \n",
    "\n",
    "for i in range(len(stars_list)):\n",
    "    epsf, fitted_stars = epsf_builder(stars_list[i])  \n",
    "    norm = simple_norm(epsf.data, 'log', percent=99.)\n",
    "    plt.imshow(epsf.data, norm=norm, origin='lower', cmap='viridis')\n",
    "    plt.colorbar()\n",
    "    plt.savefig('hh7_11_checks/EPSFs_selfconv/'+file_start[i]+'_EPSF_selfconv.png')\n",
    "    plt.close()\n",
    "    \n",
    "        #https://photutils.readthedocs.io/en/stable/psf_matching.html could be inspiration\n",
    "    #https://www.stsci.edu/files/live/sites/www/files/home/hst/instrumentation/wfc3/documentation/instrument-science-reports-isrs/_documents/2016/WFC3-2016-12.pdf can see for more...\n",
    "\n",
    "    #instead let's double check stackoverflow for now...seems complex\n",
    "    #ultimately just trying epsf cross section, like in https://stackoverflow.com/questions/18920614/plot-cross-section-through-heat-map\n",
    "\n",
    "    # Coordinates of the line we'd like to sample along\n",
    "    line = [(0, 13.5), (25, 13.5)]\n",
    "\n",
    "    # Convert the line to pixel/index coordinates\n",
    "    x, y = np.arange(epsf.data.shape[0]), np.arange(epsf.data.shape[1])\n",
    "    x_world, y_world = np.array(list(zip(*line)))\n",
    "    col = epsf.data.shape[1] * (x_world - x.min()) / x.ptp()\n",
    "    row = epsf.data.shape[0] * (y_world - y.min()) / y.ptp()\n",
    "\n",
    "    # Interpolate the line at \"num\" points...\n",
    "    num = 27\n",
    "    row, col = [np.linspace(item[0], item[1], num) for item in [row, col]]\n",
    "\n",
    "    # Plot...\n",
    "    fig, axes = plt.subplots(figsize=(10, 8), nrows=2, ncols=2)\n",
    "    fig.delaxes(axes[0,1])\n",
    "\n",
    "    axes[1,0].pcolormesh(x, y, epsf.data)\n",
    "    axes[1,0].plot(x_world, y_world, 'ro-')\n",
    "    axes[1,0].plot(y_world, x_world, 'bo-')\n",
    "    axes[1,0].axis('image')\n",
    "\n",
    "    # Extract the values along the line, using cubic interpolation\n",
    "    import scipy as sp\n",
    "    #horizontal cut\n",
    "    cross_sec_hori = sp.ndimage.map_coordinates(epsf.data, np.vstack((row, col)))\n",
    "    axes[0,0].scatter(np.arange(len(cross_sec_hori)), cross_sec_hori, color='r')\n",
    "\n",
    "    #vertical cut\n",
    "    cross_sec_vert = sp.ndimage.map_coordinates(epsf.data, np.vstack((col, row)))\n",
    "    axes[1,1].scatter(cross_sec_vert, np.arange(len(cross_sec_vert)), color='b')\n",
    "\n",
    "    plt.savefig('hh7_11_checks/psf_profiles_selfconv/'+file_start[i]+'_EPSF_selfconv.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#next, we load in some HST images\n",
    "#the hubble images\n",
    "path = 'conv_checks/164conv_*'\n",
    "files_data = [i.replace('\\\\', '/') for i in glob.glob(path)]\n",
    "print(files_data)\n",
    "\n",
    "#initializing some lists to be used\n",
    "hdu_data_list = []\n",
    "hdu_header_list = []\n",
    "\n",
    "#opening data and headers\n",
    "hdu_list = [fits.open(i) for i in files_data]\n",
    "\n",
    "#I'm using count here just to point to specific indices that I've set up...unfortunately some have different headers...\n",
    "#the only diff between the if and else cases are the indexing of the hdu's, some need 1 and some need 0\n",
    "#I've tried to group it for convience, so the the first two have the same headers, the last 3 have the same headers\n",
    "count = 0\n",
    "for hdu_data in hdu_list:\n",
    "    #reading in data for general use  and header for wcs\n",
    "    #converting by times by flam * bw from e-/sec...should get units of erg/cm^2/sec as above\n",
    "    hdu_data_list.append(hdu_data[0].data)\n",
    "    hdu_header_list.append(hdu_data[0].header)\n",
    "\n",
    "    count += 1\n",
    "\n",
    "print('loaded data!')\n",
    "\n",
    "#finally, make psfs for each star and then we determine the resolution from the PSFs\n",
    "#can be done by fitting a gaussian (or other kernel) and normalizing so integral of psf is 1\n",
    "\n",
    "#follow https://photutils.readthedocs.io/en/stable/epsf.html\n",
    "\n",
    "#now, locate spots on the images\n",
    "from astropy.nddata import NDData\n",
    "from astropy.table import Table\n",
    "from astropy.wcs.utils import skycoord_to_pixel\n",
    "from photutils.psf import extract_stars #use this to make star cutouts\n",
    "\n",
    "# nddata = NDData(data=hdu_data_list[-1], wcs=WCS(hdu_header_list[-1]))   #here reformatting data from 1.64 micron HST image\n",
    "nddata_list = [NDData(data=i, wcs=j) for i,j in zip(hdu_data_list, hdu_header_list) ]\n",
    "\n",
    "#this was made complicated bc you cannot directly go from skycoord to Table\n",
    "stars_list = []\n",
    "for nddata in nddata_list:\n",
    "\n",
    "    stars_tbl = Table(names=('x', 'y'))\n",
    "    for i in range(len(result_table)):\n",
    "        ra_dec_formatted = SkyCoord(result_table[i]['RA'][0] + ' ' + result_table[i]['DEC'][0], frame='icrs', unit=(u.hourangle, u.deg))\n",
    "        pix = skycoord_to_pixel(ra_dec_formatted, WCS(hdu_header_list[i]))\n",
    "        stars_tbl.add_row(pix)\n",
    "\n",
    "    stars = extract_stars(nddata, stars_tbl, size=25) \n",
    "    stars_list.append(stars)\n",
    "\n",
    "#finally, make psfs for each star and then we determine the resolution from the PSFs\n",
    "#can be done by fitting a gaussian (or other kernel) and normalizing so integral of psf is 1\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.visualization import simple_norm\n",
    "nrows = 1\n",
    "ncols = 3\n",
    "\n",
    "file_start = ['conv_0301_oIreproject2', 'conv_hareproject_shifted_up5_left3', 'conv_672_sIIreproject', 'conv_126_aligned', 'conv_128_aligned', 'conv_164_aligned.fits', 'f_Fe', 'f_H']\n",
    "\n",
    "for i in range(len(stars_list)):\n",
    "    fig, ax = plt.subplots(nrows=nrows, ncols=ncols, figsize=(15, 15))\n",
    "    ax = ax.ravel()\n",
    "\n",
    "    for j in range(nrows*ncols):\n",
    "        norm = simple_norm(stars_list[i][j], 'log', percent=99.)\n",
    "        ax[j].imshow(stars_list[i][j], norm=norm, origin='lower', cmap='viridis')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('hh7_11_checks/psfcutouts_164conv/'+file_start[i]+'_psfcutout_164conv.png')\n",
    "    plt.close()\n",
    "\n",
    "#attempting and failing to make an effective psf fitter\n",
    "\n",
    "#increase maxiters to smooth more and decrease oversampling to avoid issues \n",
    "from photutils.psf import EPSFBuilder\n",
    "epsf_builder = EPSFBuilder(oversampling=1, maxiters=30,\n",
    "                           progress_bar=False)  \n",
    "\n",
    "for i in range(len(stars_list)):\n",
    "    epsf, fitted_stars = epsf_builder(stars_list[i])  \n",
    "    norm = simple_norm(epsf.data, 'log', percent=99.)\n",
    "    plt.imshow(epsf.data, norm=norm, origin='lower', cmap='viridis')\n",
    "    plt.colorbar()\n",
    "    plt.savefig('hh7_11_checks/EPSFs_164conv/'+file_start[i]+'_EPSF_164conv.png')\n",
    "    plt.close()\n",
    "    \n",
    "        #https://photutils.readthedocs.io/en/stable/psf_matching.html could be inspiration\n",
    "    #https://www.stsci.edu/files/live/sites/www/files/home/hst/instrumentation/wfc3/documentation/instrument-science-reports-isrs/_documents/2016/WFC3-2016-12.pdf can see for more...\n",
    "\n",
    "    #instead let's double check stackoverflow for now...seems complex\n",
    "    #ultimately just trying epsf cross section, like in https://stackoverflow.com/questions/18920614/plot-cross-section-through-heat-map\n",
    "\n",
    "    # Coordinates of the line we'd like to sample along\n",
    "    line = [(0, 13.5), (25, 13.5)]\n",
    "\n",
    "    # Convert the line to pixel/index coordinates\n",
    "    x, y = np.arange(epsf.data.shape[0]), np.arange(epsf.data.shape[1])\n",
    "    x_world, y_world = np.array(list(zip(*line)))\n",
    "    col = epsf.data.shape[1] * (x_world - x.min()) / x.ptp()\n",
    "    row = epsf.data.shape[0] * (y_world - y.min()) / y.ptp()\n",
    "\n",
    "    # Interpolate the line at \"num\" points...\n",
    "    num = 27\n",
    "    row, col = [np.linspace(item[0], item[1], num) for item in [row, col]]\n",
    "\n",
    "    # Plot...\n",
    "    fig, axes = plt.subplots(figsize=(10, 8), nrows=2, ncols=2)\n",
    "    fig.delaxes(axes[0,1])\n",
    "\n",
    "    axes[1,0].pcolormesh(x, y, epsf.data)\n",
    "    axes[1,0].plot(x_world, y_world, 'ro-')\n",
    "    axes[1,0].plot(y_world, x_world, 'bo-')\n",
    "    axes[1,0].axis('image')\n",
    "\n",
    "    # Extract the values along the line, using cubic interpolation\n",
    "    import scipy as sp\n",
    "    #horizontal cut\n",
    "    cross_sec_hori = sp.ndimage.map_coordinates(epsf.data, np.vstack((row, col)))\n",
    "    axes[0,0].scatter(np.arange(len(cross_sec_hori)), cross_sec_hori, color='r')\n",
    "\n",
    "    #vertical cut\n",
    "    cross_sec_vert = sp.ndimage.map_coordinates(epsf.data, np.vstack((col, row)))\n",
    "    axes[1,1].scatter(cross_sec_vert, np.arange(len(cross_sec_vert)), color='b')\n",
    "\n",
    "    plt.savefig('hh7_11_checks/psf_profiles_164conv/'+file_start[i]+'_EPSF_164conv.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This shows it is about 3 to 4 pixels wide for FWHM (haven't directly measured yet)\n",
    "\n",
    "theta as in res is 1.2 * lambda / D\n",
    "If we take 1.64 microns and 2.4e6 meters, then we get an angular res of \n",
    "1.319e-6 radians ?\n",
    "Ok so we can use pixtorad of 6.217729758370198e-07 rads = 1 pix\n",
    "So we therefore divide to get 2.12 pixels\n",
    "\n",
    "So the 2.12 is perhaps a slight underestimate? Depends on the specifics of this model and the cross section, though\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
