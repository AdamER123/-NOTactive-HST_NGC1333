{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.4\n"
     ]
    }
   ],
   "source": [
    "#check what version of python you're using - I'm using 3.7.3\n",
    "from platform import python_version\n",
    "print(python_version())\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "#importing libraries\n",
    "from astropy.io import fits\n",
    "from astropy.convolution import convolve, Gaussian2DKernel\n",
    "from astropy.wcs import WCS\n",
    "from astropy.nddata import Cutout2D\n",
    "from reproject import reproject_exact  #a package that can be added to astropy using anaconda or pip (see their docs pg)\n",
    "from reproject import reproject_interp\n",
    "\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image plotting in python\n",
    "def implot(data, w, wcscond, vmax_p, vmin_p):\n",
    "    fig = plt.figure()\n",
    "    \n",
    "    if  wcscond == True:\n",
    "        fig.add_subplot(111, projection=w)\n",
    "    else:\n",
    "        fig.add_subplot(111)\n",
    "    \n",
    "    #for christmas turn on GnRd\n",
    "    #plt.cm.get_cmap('Blues', 6) is another option\n",
    "    #can also use RdBu...\n",
    "    #otherwise just use plt.cm.viridis b/c it works\n",
    "    plt.imshow(data, origin='lower', cmap=plt.cm.viridis, vmin =vmin_p, vmax=vmax_p)\n",
    "    plt.colorbar()\n",
    "    plt.xlabel('RA')\n",
    "    plt.ylabel('Dec')\n",
    "\n",
    "    \n",
    "# #finding the path to every fits images in a directory\n",
    "def im_name_finder(path, file_type):\n",
    "    #Using glob (it's a unix command similar to ls)\n",
    "    #WARNING: using recursive=True...depending how many images you use this could be very slow, it's recommended not to have too many subfolders\n",
    "    #if needed, some example code is commented towards the latter half of this code that could help make an alternative\n",
    "    all_names = glob.glob(path, recursive=True)\n",
    "\n",
    "    #IMPORTANT: Using \"fit\" here because it is inclusive of both fits and FIT...some files end in \"FIT\" and need to be included\n",
    "    #using s.lower() include uppercase names\n",
    "    im_names = [s for s in all_names if 'fit' in s.lower()]\n",
    "\n",
    "    return im_names\n",
    "\n",
    "\n",
    "# In[27]:\n",
    "\n",
    "#setting up a new fits file to be saved and viewed in DS9\n",
    "#primarily to save the image we reprojected, but can also be used to save the convolved images\n",
    "def fits_saver(array, wcs_header, name, save_path):\n",
    "    '''\n",
    "    array is a 2d array of data - could be from reprojecting one image onto another or from convolution\n",
    "    wcs_header is a header containing the wcs coords of the image that we projected onto or of the orig image (if from the convolution)\n",
    "    name is the path to some image you're using. It will get string split at the / character, and the func only takes the last element of that splitting\n",
    "    save_path is the folder you want to save to...recommended to also add something to the start of the images names to make it clear what you did to them (e.g. 'Regridded/regrid_')\n",
    "    '''\n",
    "\n",
    "    #creating a new file and adding the reprojected array of data as well as the WCS that we projected onto\n",
    "    hdu_new = fits.PrimaryHDU(array, header=wcs_header)\n",
    "    hdul = fits.HDUList([hdu_new])\n",
    "\n",
    "    #saving the file\n",
    "    new_filename = name.split('/')[-1]  #grabs the file name we were using from before\n",
    "    hdul.writeto(save_path+new_filename, overwrite=True)\n",
    "\n",
    "    return (save_path+new_filename)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Keyword 'D001SCAL' not found.\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-5eb11abc1b44>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;31m#hdu1_pix = hdu1.header['CDELT2'] #the pixel size in degrees, CDELT is the keyword for Spitzer images\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;31m#hdu1_pix_torad = hdu1_pix * np.pi / 180.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m \u001b[0mhdu1_pix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhdu1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheader\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'D001SCAL'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m#pixel size in arcsecs, but D001SCAL is the keyword for Hubble images\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m \u001b[0mhdu1_pix_torad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhdu1_pix\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m206265.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[0mhdu1_fnu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhdu1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheader\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'PHOTFNU'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\envs\\mypython3\\lib\\site-packages\\astropy\\io\\fits\\header.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    146\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m             \u001b[0mkeyword\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 148\u001b[1;33m         \u001b[0mcard\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cards\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cardindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    149\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcard\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfield_specifier\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mkeyword\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mcard\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrawkeyword\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m             \u001b[1;31m# This is RVKC; if only the top-level keyword was specified return\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\envs\\mypython3\\lib\\site-packages\\astropy\\io\\fits\\header.py\u001b[0m in \u001b[0;36m_cardindex\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1706\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1707\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1708\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Keyword {keyword!r} not found.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1709\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1710\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"Keyword 'D001SCAL' not found.\""
     ]
    }
   ],
   "source": [
    "# In[21]:\n",
    "#declaring noise: measured from the RMS of a region of empty sky while opening the image in DS9\n",
    "#these are newly taken from the HH 6 images...\n",
    "# noise_126 = 0.0465246\n",
    "# noise_128 = 0.04733\n",
    "# noise_164 = 0.0561296\n",
    "\n",
    "#from the regridded images...\n",
    "noise_126 = 2.6e-18 #* 0.496 #  0.216037 / 4.25e10 #times by throughput\n",
    "noise_128 = 2.75e-18 #* 0.521 # 0.258513 / 4.25e10 #times by throughput\n",
    "noise_164 = 5.766e-18  #* 0.470 # 0.39321 / 4.25e10 #times by throughput\n",
    "noise_halpha = 4.4e-20 #* 0.242  # 0.302712 / 4.25e10 #multiplied these by throughputs\n",
    "#converting units for reference\n",
    "#hdu1_conv_scaled = hdu1_conv_scaled * hdu1_fnu / 1e6 #converting to MJy\n",
    "#hdu1_conv_scaled = hdu1_conv_scaled / hdu1_pix**2. * 4.25e10 #dividing out sr, D001SCAL is key for pixel size in arcsec\n",
    "\n",
    "\n",
    "\n",
    "#EX: grabbing all the fits image paths in a directory, so they can be looped through and their data opened\n",
    "#set your path to some directory with images (the images can be in subdirectories)\n",
    "#using ** will grab all files even in subdirectories...WARNING this will take longer\n",
    "path = '../../../ngc1333_fits/'\n",
    "im_names_hub_dash = im_name_finder(path+'*', 'fit')\n",
    "im_names_hub_dash = [i.replace('\\\\', '/') for i in im_names_hub_dash]\n",
    "im_names_hub = [path+'126_image.fits', path+'128_image.fits', path+'164_image.fits', path+'halph_hart_image.fits']\n",
    "\n",
    "\n",
    "# In[28]:\n",
    "\n",
    "#Minimal loop through all the images, including a try/except in case an image is faulty for whatever reason\n",
    "#IMPORTANT: A more detailed example between two single images is at the end of this code with many more comments\n",
    "\n",
    "#First, we need to setup the image we're projecting ONTO\n",
    "#This will be the same no matter the loop, so only need to do this once\n",
    "#low_res = [x for x in im_names_spitz if 'n1333_lh_3_SiII_' in x][0]  #finding the lowest res image - LH and long lambda, so [SiII]\n",
    "\n",
    "#126\n",
    "#hdu1 = fits.open(low_res)[0]\n",
    "low_res = im_names_hub_dash[0]   #Could also let this be a hubble image...if so, see the hubble loop below for how to setup grabbing the data, header, pixel conversion from the hdu\n",
    "hdu1 = fits.open(low_res)\n",
    "\n",
    "#hdu1_pix = hdu1.header['CDELT2'] #the pixel size in degrees, CDELT is the keyword for Spitzer images\n",
    "#hdu1_pix_torad = hdu1_pix * np.pi / 180.\n",
    "hdu1_pix = hdu1[0].header['D001SCAL'] #pixel size in arcsecs, but D001SCAL is the keyword for Hubble images\n",
    "hdu1_pix_torad = hdu1_pix / 206265.\n",
    "hdu1_fnu = hdu1[0].header['PHOTFNU']\n",
    "hdu1_flam = hdu1[0].header['PHOTFLAM']\n",
    "hdu1_bw = hdu1[0].header['PHOTBW']\n",
    "\n",
    "low_res = im_names_hub[0]\n",
    "hdu1 = fits.open(low_res)\n",
    "hdu1_data = hdu1[0].data\n",
    "hdu1_header = hdu1[0].header\n",
    "\n",
    "#converting noise units\n",
    "# noise_126 = noise_126 * hdu1_fnu / 1e6\n",
    "noise_126 = noise_126 #* hdu1_pix_torad**2. * hdu1_bw\n",
    "\n",
    "\n",
    "#128\n",
    "name = im_names_hub_dash[2]   #Could also let this be a hubble image...if so, see the hubble loop below for how to setup grabbing the data, header, pixel conversion from the hdu\n",
    "hdu2 = fits.open(name)\n",
    "\n",
    "#reading in data\n",
    "hdu2_pix = hdu2[0].header['D001SCAL'] #same as above line, but D001SCAL is the keyword for Hubble images\n",
    "hdu2_pix_torad = hdu2_pix / 206265.\n",
    "hdu2_fnu = hdu2[0].header['PHOTFNU']\n",
    "hdu2_flam = hdu2[0].header['PHOTFLAM']\n",
    "hdu2_bw = hdu2[0].header['PHOTBW']\n",
    "\n",
    "\n",
    "#now working with long exposure image (necessary for working with data based on header)\n",
    "name = im_names_hub[1]\n",
    "hdu2 = fits.open(name)\n",
    "hdu2_data = hdu2[0].data\n",
    "hdu2_header = hdu2[0].header\n",
    "\n",
    "#converting noise units\n",
    "# noise_128 = noise_128 * hdu2_fnu / 1e6\n",
    "noise_128 = noise_128 #* hdu2_pix_torad**2. * hdu2_bw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../../ngc1333_fits/unregridded/halph_hart_image.fits'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-556f82d87317>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#need to do halpha image as well...\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# hdu3 = fits.open(im_names_hub_dash[6])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mhdu3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfits\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../../../ngc1333_fits/unregridded/halph_hart_image.fits'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#reading in data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\envs\\mypython3\\lib\\site-packages\\astropy\\io\\fits\\hdu\\hdulist.py\u001b[0m in \u001b[0;36mfitsopen\u001b[1;34m(name, mode, memmap, save_backup, cache, lazy_load_hdus, **kwargs)\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m     return HDUList.fromfile(name, mode, memmap, save_backup, cache,\n\u001b[1;32m--> 165\u001b[1;33m                             lazy_load_hdus, **kwargs)\n\u001b[0m\u001b[0;32m    166\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\envs\\mypython3\\lib\\site-packages\\astropy\\io\\fits\\hdu\\hdulist.py\u001b[0m in \u001b[0;36mfromfile\u001b[1;34m(cls, fileobj, mode, memmap, save_backup, cache, lazy_load_hdus, **kwargs)\u001b[0m\n\u001b[0;32m    403\u001b[0m         return cls._readfrom(fileobj=fileobj, mode=mode, memmap=memmap,\n\u001b[0;32m    404\u001b[0m                              \u001b[0msave_backup\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msave_backup\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcache\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 405\u001b[1;33m                              lazy_load_hdus=lazy_load_hdus, **kwargs)\n\u001b[0m\u001b[0;32m    406\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    407\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\envs\\mypython3\\lib\\site-packages\\astropy\\io\\fits\\hdu\\hdulist.py\u001b[0m in \u001b[0;36m_readfrom\u001b[1;34m(cls, fileobj, data, mode, memmap, save_backup, cache, lazy_load_hdus, **kwargs)\u001b[0m\n\u001b[0;32m   1052\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_File\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m                 \u001b[1;31m# instantiate a FITS file object (ffo)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1054\u001b[1;33m                 \u001b[0mfileobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_File\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmemmap\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcache\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1055\u001b[0m             \u001b[1;31m# The Astropy mode is determined by the _File initializer if the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1056\u001b[0m             \u001b[1;31m# supplied mode was None\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\envs\\mypython3\\lib\\site-packages\\astropy\\utils\\decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    533\u001b[0m                     \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwarning_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 535\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    536\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    537\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\envs\\mypython3\\lib\\site-packages\\astropy\\io\\fits\\file.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, fileobj, mode, memmap, overwrite, cache)\u001b[0m\n\u001b[0;32m    191\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_fileobj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 193\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_filename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    194\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_filelike\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\envs\\mypython3\\lib\\site-packages\\astropy\\io\\fits\\file.py\u001b[0m in \u001b[0;36m_open_filename\u001b[1;34m(self, filename, mode, overwrite)\u001b[0m\n\u001b[0;32m    572\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    573\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_try_read_compressed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmagic\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mext\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 574\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfileobj_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIO_FITS_MODES\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    575\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose_on_error\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    576\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\envs\\mypython3\\lib\\site-packages\\astropy\\io\\fits\\util.py\u001b[0m in \u001b[0;36mfileobj_open\u001b[1;34m(filename, mode)\u001b[0m\n\u001b[0;32m    394\u001b[0m     \"\"\"\n\u001b[0;32m    395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 396\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffering\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    397\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../../ngc1333_fits/unregridded/halph_hart_image.fits'"
     ]
    }
   ],
   "source": [
    "#halpha\n",
    "#need to do halpha image as well...\n",
    "# hdu3 = fits.open(im_names_hub_dash[6])\n",
    "hdu3 = fits.open('../../../ngc1333_fits/unregridded/halph_hart_image.fits')\n",
    "\n",
    "#reading in data\n",
    "hdu3_pix = hdu3[0].header['D001SCAL'] #same as above line, but D001SCAL is the keyword for Hubble images\n",
    "hdu3_pix_torad = hdu3_pix / 206265.\n",
    "\n",
    "#under science header of the original image\n",
    "hdu3_fnu = hdu3[1].header['PHOTFNU']\n",
    "hdu3_flam = hdu3[1].header['PHOTFLAM']\n",
    "hdu3_bw = hdu3[1].header['PHOTBW']\n",
    "\n",
    "#opening the regridded image?\n",
    "name2 = im_names_hub[3]\n",
    "hdu3 = fits.open(name2)\n",
    "hdu3_data = hdu3[0].data\n",
    "hdu3_header = hdu3[0].header\n",
    "\n",
    "#converting noise units\n",
    "noise_halpha = noise_halpha #* hdu3_pix_torad**2. * hdu3_bw\n",
    "\n",
    "\n",
    "\n",
    "#164\n",
    "#need to do halpha image as well...\n",
    "hdu4 = fits.open(im_names_hub_dash[4])\n",
    "\n",
    "#reading in data\n",
    "hdu4_pix = hdu4[0].header['D001SCAL'] #same as above line, but D001SCAL is the keyword for Hubble images\n",
    "hdu4_pix_torad = hdu4_pix / 206265.\n",
    "\n",
    "#under science header of the original image\n",
    "hdu4_fnu = hdu4[0].header['PHOTFNU']\n",
    "hdu4_flam = hdu4[0].header['PHOTFLAM']\n",
    "hdu4_bw = hdu4[0].header['PHOTBW']\n",
    "\n",
    "#opening the regridded image?\n",
    "name3 = im_names_hub[2]\n",
    "hdu4 = fits.open(name3)\n",
    "hdu4_data = hdu4[0].data\n",
    "hdu4_header = hdu4[0].header\n",
    "\n",
    "#converting noise units\n",
    "noise_164 = noise_164 #* hdu4_pix_torad**2. * hdu4_bw\n",
    "\n",
    "\n",
    "\n",
    "#reprojection of one hdu using the header (coords and pixels) of another\n",
    "#The first input is the path to the file we're reprojecting. The second input is the header of the image we're projecting ONTO\n",
    "#you'll need to set the WCS to be that of the header you're basing this off of...ie the header\n",
    "\n",
    "#file_start = 'Convolved_Images_Hub/conv_'\n",
    "#conv2_path = file_start + name.split('/')[-1]\n",
    "res_str = '_flam' #string to be used to note the resolution of the image we expect\n",
    "\n",
    "#FeII 1.26\n",
    "w = WCS(hdu1_header)\n",
    "wcs_header = w.to_header()\n",
    "file_start = '../../Convolved_Images_Hub/conv_'+res_str+'_'\n",
    "hdu1_conv = fits.open(file_start + low_res.split('/')[-1])\n",
    "hdu1_conv_scaled = hdu1_conv[0].data #* hdu1_pix_torad**2.   #* hdu1_bw #/ 4.25e10\n",
    "\n",
    "#hbeta, 1.28\n",
    " #para is False for large images (like these hubble ones)\n",
    "#output is array (a 2D array of data) and footprint (the footprint from the analysis)\n",
    "file_start = '../../Regridded_Hub/regrid_'+res_str+'_'\n",
    "hdu_regrid_hub = fits.open(file_start + name.split('/')[-1])\n",
    "array = hdu_regrid_hub[0].data #* hdu2_pix_torad**2.  # * hdu2_bw # / 4.25e10   \n",
    "\n",
    "#halpha, 0.656\n",
    "hdu_regrid_hub2 = fits.open(file_start + name2.split('/')[-1])\n",
    "array2 = hdu_regrid_hub2[0].data #* hdu3_pix_torad**2.  # * hdu3_bw  # / 4.25e10\n",
    "\n",
    "#halpha, 1.64\n",
    "hdu_regrid_hub3 = fits.open(file_start + name3.split('/')[-1])\n",
    "array3 = hdu_regrid_hub3[0].data #* hdu4_pix_torad**2.  # * hdu4_bw  # / 4.25e10\n",
    "\n",
    "\n",
    "\n",
    "#now that we have a reprojected hubble image for hdu2 and both are convolved, need to\n",
    "#divide one by the other...then can use the same wcs header that we projected onto (hdu1's)!\n",
    "#getting rid of nan values\n",
    "where_are_NaNs = np.isnan(array)\n",
    "array[where_are_NaNs] = 0.\n",
    "\n",
    "where_are_NaNs = np.isnan(array2)\n",
    "array2[where_are_NaNs] = 0.\n",
    "\n",
    "where_are_NaNs = np.isnan(array3)\n",
    "array3[where_are_NaNs] = 0.\n",
    "\n",
    "where_are_NaNs = np.isnan(hdu1_conv_scaled)\n",
    "hdu1_conv_scaled[where_are_NaNs] = 0.\n",
    "\n",
    "#print(perc * np.max(array))\n",
    "#array[array < (perc * np.max(array))] = 0.  #only taking values greater than some percent of the maximum\n",
    "\n",
    "#scaling by the signal to noise\n",
    "perc = 0.2 #this tends to work?? Maybe can change...\n",
    "perc2 = 0.1\n",
    "\n",
    "array[array < noise_128*perc] = 0.\n",
    "array2[array2 < noise_halpha*perc] = 0.\n",
    "array3[array3 < noise_164*perc] = 0.\n",
    "hdu1_conv_scaled[hdu1_conv_scaled < noise_126*perc] = 0.\n",
    "\n",
    "#getting rid of 0 values\n",
    "# array[array < 0.] = 0.\n",
    "# array2[array2 < 0.] = 0.\n",
    "# array3[array3 < 0.] = 0.\n",
    "# hdu1_conv_scaled[hdu1_conv_scaled < 0.] = 0.\n",
    "\n",
    "    \n",
    "    \n",
    "#cutting out part of the image...HH 10 or HH 7 in order to make scattered light image\n",
    "#purpose is to find max of the region to use to normalize the image\n",
    "#     count = 0\n",
    "#     hh10_max = []\n",
    "#     coords = [(560, 460), (13, 13)] #these coordinates worked before...hopefully works again?\n",
    "#     coords = [(556, 136), (15, 15)] #hh7, 556,135 and 8, 25\n",
    "#     coords = [(535, 546), (10, 10)] #hh11\n",
    "\n",
    "flux01 = array  #*1e6*1e-23*hdu2_bw #normalizing to max and converting units to lam*flam #hdu1_conv_scaled - eps * array\n",
    "flux02 = array2  #*1e6*1e-23*hdu3_bw #normalizing to max and converting units to nu*fnu\n",
    "#     data_subtrac = flux01 - flux02\n",
    "#     data_subtrac = (array - array.min()) / (array.max() - array.min())  - (array2 - array2.min()) / (array2.max() - array2.min())\n",
    "#     data_ratio = np.divide(flux01, flux02, out=np.zeros_like(flux02), where=flux02!=0.) #need to do np.divide to guarantee we get no divide by zero issue...\n",
    "\n",
    "#plotting image to check\n",
    "#order is halpha, 1.26, 1.28, 1.64...\n",
    "implot(array2, w, False, np.mean(array2))\n",
    "implot(hdu1_conv_scaled, w, False, np.mean(hdu1_conv_scaled)) \n",
    "implot(array, w, False, np.mean(array)) \n",
    "implot(array3, w, False, np.mean(array3)) \n",
    "\n",
    "# remember to have the right header with the wcs below and that it matches the one we're projecting ONTO\n",
    "#     w = WCS(hdu2_header)\n",
    "#     wcs_header = w.to_header()\n",
    "#     save_path = './'  #See fits_saver's \"save_path\" description for explanation\n",
    "#     fits_saver(data_subtrac, wcs_header, 'hub_noleakage_imscatt__ston_'+str(perc)+'_scale3.fits', save_path)  #saving the reprojected image\n",
    "sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "This cell was my initial tests for a single pixel fitting\n",
    "\n",
    "Using \n",
    "https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.newton_krylov.html#scipy.optimize.newton_krylovfor a non linear solver…\n",
    "\n",
    "Try the algebraic solution… open up 4 images, \n",
    "put cursorover same place, see what values are…\n",
    "\n",
    "Halpha of 12*.3 (can reduce to reduce negative amt)\n",
    "1.2six of 1.3\n",
    "Pabeta of 1.2  \n",
    "1.six4 of 3\n",
    "\n",
    "Q: How long it takes to 12k iterations?\n",
    "That’s at me…See how long it takes on my computer \n",
    "vs. Inanna…fora bounded single pixel problem…\n",
    "\n",
    "'''\n",
    "\n",
    "#ordering arrays by wavelength...\n",
    "#     implot(array2, w, False, np.mean(array2))\n",
    "#     implot(hdu1_conv_scaled, w, False, np.mean(hdu1_conv_scaled)) \n",
    "#     implot(array, w, False, np.mean(array)) \n",
    "#     implot(array3, w, False, np.mean(array3)) \n",
    "\n",
    "cen_x = 690 # 580\n",
    "cen_y = 440 # 370\n",
    "del_x = 1 #200 # 55\n",
    "del_y = 1 #150 #100\n",
    "\n",
    "# #HH9? The arcy feature thing\n",
    "cutout1 = Cutout2D(array2, (cen_x, cen_y), (del_y, del_x), wcs = w.celestial)\n",
    "datacut1 = cutout1.data\n",
    "wcscut1 = cutout1.wcs \n",
    "\n",
    "cutout2 = Cutout2D(hdu1_conv_scaled, (cen_x, cen_y), (del_y, del_x), wcs = w.celestial)\n",
    "datacut2 = cutout2.data\n",
    "wcscut2 = cutout2.wcs \n",
    "\n",
    "cutout3 = Cutout2D(array, (cen_x, cen_y), (del_y, del_x), wcs = w.celestial)\n",
    "datacut3 = cutout3.data\n",
    "wcscut3 = cutout3.wcs \n",
    "\n",
    "cutout4 = Cutout2D(array3, (cen_x, cen_y), (del_y, del_x), wcs = w.celestial)\n",
    "datacut4 = cutout4.data\n",
    "wcscut4 = cutout4.wcs \n",
    "\n",
    "#plotting cutouts\n",
    "# implot(datacut1, wcscut1, False, (datacut1)) \n",
    "# implot(datacut2, wcscut2, False, (datacut2)) \n",
    "# implot(datacut3, wcscut3, False, (datacut3)) \n",
    "# implot(datacut4, wcscut4, False, (datacut4)) \n",
    "\n",
    "\n",
    "\n",
    "#global vars for func\n",
    "h = 6.626e-34 #SI units, J*sec\n",
    "c = 2.998e8 #SI units, m/s\n",
    "k_B = 1.38e-23 #SI, J/K\n",
    "\n",
    "#list of wavelengths for each filter being used\n",
    "lam_arr = 1e-6 * np.array([0.656, 1.26, 1.28, 1.64])\n",
    "\n",
    "#func for planck's law\n",
    "def B_lam(lam, temp=1000, const =1e5):\n",
    "    return const * 2. * h * c**2. / lam**5. * 1. / (np.exp((h * c) / (lam*k_B*temp)) - 1.)\n",
    "\n",
    "\n",
    "#continuum of filament fluxes near hh 8\n",
    "cont_flux = np.array([np.mean(datacut1), np.mean(datacut2), np.mean(datacut3), np.mean(datacut4)] )\n",
    "print(cont_flux)\n",
    "# cont_flux = np.array([np.max(datacut1), np.max(datacut2), np.max(datacut3), np.max(datacut4)] )\n",
    "\n",
    "#to convert from MJy to MJy / sr\n",
    "sr_convert = 1. / np.array([hdu3_pix**2., hdu1_pix**2., hdu2_pix**2., hdu4_pix**2.])\n",
    "#to convert from MJy to W/m^2/Hz\n",
    "jy_to_si = 1e-26 * 1e6\n",
    "#convert contflux\n",
    "cont_flux = cont_flux * jy_to_si #* sr_convert\n",
    "print(sr_convert)\n",
    "print('continuum intensity: ', c / lam_arr**2. * cont_flux)\n",
    "\n",
    "\n",
    "\n",
    "#attempting many solvers\n",
    "from scipy.optimize import newton_krylov\n",
    "from scipy.optimize import minimize\n",
    "from scipy.optimize import curve_fit\n",
    "# xin = [500, 4.105e12] #K, const...initial guesses\n",
    "xin = [2.44402408e03, 2.56589326e-12]\n",
    "popt, pcov = curve_fit(B_lam, lam_arr, c / lam_arr**2. * cont_flux, p0=xin) #solving!\n",
    "print('blackbody fit: ', popt) #output\n",
    "perr = np.sqrt(np.diag(pcov))\n",
    "print('1 sigma: ', perr)\n",
    "\n",
    "\n",
    "#plotting\n",
    "plt.figure(212) #establish new figure\n",
    "#plot to show results\n",
    "plt.scatter(1e6*lam_arr, c / lam_arr**2. * cont_flux, label = 'observation') #the data\n",
    "\n",
    "#plotting planck's law with fit params\n",
    "lam_interp = np.linspace(lam_arr[0], lam_arr[-1])\n",
    "plt.plot(1e6*lam_interp, B_lam(lam_interp, popt[0], popt[1]), linestyle='--', label = 'Blackbody Fit')\n",
    "\n",
    "#formatting\n",
    "plt.legend(loc='best')\n",
    "plt.ylim(min(c / lam_arr**2. * cont_flux) - 9e-12, max(c / lam_arr**2. * cont_flux) + 3e-11)\n",
    "plt.xlim(1e6*lam_arr[0], 1e6*lam_arr[-1])\n",
    "plt.xlabel(r'$\\lambda$ (microns)')\n",
    "plt.ylabel(r'$\\rm {B}_{\\lambda}$ (W/m^3/sr)')\n",
    "\n",
    "\n",
    "\n",
    "#global vars for func\n",
    "R_Fe = 2.0\n",
    "R_H = 17.5\n",
    "y_arr = [0.47245, 0.77307, 0.78015, 0.85001]\n",
    "T = popt[0]\n",
    "\n",
    "#func for non-linear equation...\n",
    "def scatt_func(lam_arr, C, A_V, f_H, f_Fe):\n",
    "    return np.array([\n",
    "        (R_H * f_H + B_lam(lam_arr[0], T, C)) * y_arr[0]**A_V, \n",
    "        (R_Fe * f_Fe + B_lam(lam_arr[1], T, C)) * y_arr[1]**A_V,\n",
    "        (f_H + B_lam(lam_arr[2], T, C)) * y_arr[2]**A_V,\n",
    "        (f_Fe + B_lam(lam_arr[3], T, C)) * y_arr[3]**A_V \n",
    "        ])\n",
    "\n",
    "#attempting to fit using curve_fit\n",
    "xin = [1.04686128e-23, 10, 1e-10, 1e-10]\n",
    "popt, pcov = curve_fit(scatt_func, lam_arr, c / lam_arr**2. * cont_flux, p0=xin) #solving!\n",
    "print('curve_fit attempt: ', popt)\n",
    "\n",
    "C_fit, A_V_fit, f_H_fit, f_Fe_fit = popt\n",
    "# extinc_factor = y_arr**A_V\n",
    "print(f_Fe_fit / f_H_fit)\n",
    "\n",
    "#chi^2 test...against curve_fit\n",
    "obs_intens = c / lam_arr**2. * cont_flux\n",
    "theory_intens = scatt_func(lam_arr, C_fit, A_V_fit, f_H_fit, f_Fe_fit)\n",
    "n_obs = len(obs_intens)\n",
    "chi2 = np.sum((obs_intens - theory_intens)**2.)\n",
    "print('sum(squared diffs): ', chi2)\n",
    "\n",
    "\n",
    "\n",
    "#setting up a figure to plot on these fits...\n",
    "plt.figure(213) #establish new figure\n",
    "#plot to show results\n",
    "plt.scatter(1e6*lam_arr, c / lam_arr**2. * cont_flux, label = 'Observed') #the data\n",
    "# plt.scatter(1e6*lam_arr, scatt_func(lam_arr, C_fit, A_V_fit, f_H_fit, f_Fe_fit), label = 'Curve_Fit', s=20) #curve_fit method\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#redefining function to setup a system of equations equal to 0 \n",
    "def scatt_equ_solver(input_arr):\n",
    "    C, A_V, f_H, f_Fe = input_arr\n",
    "    equ_sys = c / lam_arr**2. * cont_flux - np.array([\n",
    "        (R_H * f_H + B_lam(lam_arr[0], T, C)) * y_arr[0]**A_V, \n",
    "        (R_Fe * f_Fe + B_lam(lam_arr[1], T, C)) * y_arr[1]**A_V,\n",
    "        (f_H + B_lam(lam_arr[2], T, C)) * y_arr[2]**A_V,\n",
    "        (f_Fe + B_lam(lam_arr[3], T, C)) * y_arr[3]**A_V \n",
    "        ])\n",
    "#     print(equ_sys)\n",
    "    return equ_sys\n",
    "\n",
    "#trying to solve system with non-lin solver\n",
    "from scipy.optimize import newton_krylov\n",
    "from scipy.optimize import anderson\n",
    "from scipy.optimize import broyden1\n",
    "from scipy.optimize import broyden2\n",
    "xin1 = [-1.97416054e-23,  5.23938071,  8.62153822e-11,  6.25492719e-11] #initial guess\n",
    "xin2 = [2e-23, 5.2, 9e-11, 6.3e-11] #initial guess\n",
    "xin3 = [2e-22, 2, 5e-11, 5e-11] #initial guess\n",
    "xin4 = [1e-10, 5, 1e-5, 1e-5] #initial guess\n",
    "xin5 = [2e-23, 10, 1e-12, 1e-12] #initial guess\n",
    "xin_list = [xin1, xin2, xin3, xin4, xin5]\n",
    "\n",
    "'''\n",
    "Notes from testing newton-krylov...of possible methods one can adjust\n",
    "#default: max iter can be 30-100, step can be 1e-10 to 1e-14\n",
    "#for all except cgs, can use iter of 10,000 or 100,000\\\n",
    "#for cgs can use 5000\n",
    "#that said, cgs isn't great, gmres and bicgstab seem best\n",
    "#min f_tol = 4.95e-12...maxiter with bicgstab can go up to say 100000...seems to level off at about 300 to 1000? checking...\n",
    "'''\n",
    "met = ['lgmres', 'gmres', 'bicgstab', 'cgs', 'minres']\n",
    "k = met[2]\n",
    "\n",
    "#loop testing different numbers of iterations\n",
    "iter_list = [1, 5, 10, 100, 200]\n",
    "# for i in [1, 5, 10, 100, 200]:\n",
    "i = 100\n",
    "# for j in range(len(xin_list)):\n",
    "#     for k in met:\n",
    "#         try:\n",
    "#             print('loop: ', i, k)\n",
    "solved = newton_krylov(scatt_equ_solver, [1.47240353e-22,  6.81302988,  5.51609301e-10,  2.99527923e-10], iter = i, method=k) #non-lin solver\n",
    "# solved = newton_krylov(scatt_equ_solver, xin_list[0], iter = i, method=k) #non-lin solver\n",
    "# solved = anderson(scatt_equ_solver, xin_list[0], f_tol=9e-12) #non-lin solver\n",
    "# solved = broyden1(scatt_equ_solver, xin_list[-1], f_tol=1e-11) #non-lin solver\n",
    "# solved = broyden2(scatt_equ_solver, xin_list[0], iter = i) #non-lin solver\n",
    "\n",
    "print('non-linear attempt: ', solved)\n",
    "\n",
    "#separating fit into diff variables...calculating a sum of squared diffs\n",
    "C_nk, A_V_nk, f_H_nk, f_Fe_nk = solved\n",
    "print('fit intensities: ', scatt_func(lam_arr, C_nk, A_V_nk, f_H_nk, f_Fe_nk))\n",
    "#calculating sum of squared diffs...against newton-krylov\n",
    "theory_intens = scatt_func(lam_arr, C_nk, A_V_nk, f_H_nk, f_Fe_nk)\n",
    "chi2 = np.sum((obs_intens - theory_intens)**2.)\n",
    "print('sum(squared diffs): ', chi2)\n",
    "\n",
    "# extinc_factor = y_arr**A_V\n",
    "print(f_Fe_nk / f_H_nk)\n",
    "#\"sanity check\" for founds on Fe/H\n",
    "\n",
    "\n",
    "#check how much time this took\n",
    "# stop = timeit.default_timer()\n",
    "# print('Time: ', stop - start)  \n",
    "\n",
    "\n",
    "#plotting non-linear fit to intensity\n",
    "# lam_interp = np.linspace(lam_arr[0], lam_arr[-1])\n",
    "plt.scatter(1e6*lam_arr, scatt_func(lam_arr, C_nk, A_V_nk, f_H_nk, f_Fe_nk), label = 'N-K, iter='+str(i), s=20)\n",
    "#             print('success')\n",
    "#         except: \n",
    "#             print('error')\n",
    "\n",
    "#         print('RESET')\n",
    "#formatting our plot\n",
    "plt.legend(loc='best')\n",
    "plt.ylim(min(c / lam_arr**2. * cont_flux) - 3e-12, max(c / lam_arr**2. * cont_flux) + 3e-12)\n",
    "plt.xlim(1e6*lam_arr[0], 1e6*lam_arr[-1])\n",
    "plt.xlabel(r'$\\lambda$ (microns)')\n",
    "plt.ylabel(r'$\\rm Intensity$ (W/m^3/sr)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this cell is my tests for trying different initial conditions for a single pixel by hand\n",
    "\n",
    "xin = [1.97416054e-23,  5.23938071,  8.62153822e-11,  6.25492719e-11] #result from curve_fit\n",
    "xin = [1.684E-23, 5.000, 3.174E-11, 2.329E-11] #result from default tester\n",
    "# xin = [-1.14964844e-23,  4.91891410,  6.89021847e-11,  5.22945372e-11] #plugging back fit from code into code\n",
    "# xin = [-1.32359021e-23,  5.00547418,  7.09386516e-11,  5.52949364e-11] #from using default tester result and iter = 1000\n",
    "xin = [-1.14964844e-13,  6,  1.89021847e-10,  1.22945372e-10]\n",
    "# [-3.92228753e-23  5.65802773e+00  1.22455752e-10  8.37374631e-11] #set resulting from the above parameters\n",
    "# xin = [-3.92228753e-23,  6,  1.89021847e-10,  1.22945372e-10]\n",
    "\n",
    "solved = newton_krylov(scatt_equ_solver, xin, iter = 1000, method='bicgstab') #non-lin solver\n",
    "C_nk, A_V_nk, f_H_nk, f_Fe_nk = solved\n",
    "print('non-linear attempt: ', solved)\n",
    "print('fit intensities: ', scatt_func(lam_arr, C_nk, A_V_nk, f_H_nk, f_Fe_nk))\n",
    "#calculating sum of squared diffs...against newton-krylov\n",
    "theory_intens = scatt_func(lam_arr, C_nk, A_V_nk, f_H_nk, f_Fe_nk)\n",
    "chi2 = np.sum((obs_intens - theory_intens)**2.)\n",
    "print('sum(squared diffs): ', chi2)\n",
    "\n",
    "#setting up a figure to plot on these fits...\n",
    "plt.figure(213) #establish new figure\n",
    "#plot to show results\n",
    "plt.scatter(1e6*lam_arr, c / lam_arr**2. * cont_flux, label = 'Observed') #the data\n",
    "# plt.scatter(1e6*lam_arr, scatt_func(lam_arr, C_fit, A_V_fit, f_H_fit, f_Fe_fit), label = 'Curve_Fit', s=20) #curve_fit method\n",
    "\n",
    "#plotting non-linear fit to intensity\n",
    "# lam_interp = np.linspace(lam_arr[0], lam_arr[-1])\n",
    "plt.scatter(1e6*lam_arr, scatt_func(lam_arr, C_nk, A_V_nk, f_H_nk, f_Fe_nk), label = 'N-K', s=20)\n",
    "#             print('success')\n",
    "#         except: \n",
    "#             print('error')\n",
    "\n",
    "#         print('RESET')\n",
    "#formatting our plot\n",
    "plt.legend(loc='best')\n",
    "plt.ylim(1e-12, 5e-11)\n",
    "plt.xlim(1e6*lam_arr[0], 1e6*lam_arr[-1])\n",
    "plt.xlabel(r'$\\lambda$ (microns)')\n",
    "plt.ylabel(r'$\\rm Intensity$ (W/m^3/sr)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#This cell is me trying to test a pixel fit for a set of specific pixels by hand\n",
    "\n",
    "'''\n",
    "Using \n",
    "https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.newton_krylov.html#scipy.optimize.newton_krylovfor a non linear solver…\n",
    "\n",
    "Try the algebraic solution… open up 4 images, \n",
    "put cursorover same place, see what values are…\n",
    "\n",
    "Halpha of 12*.3 (can reduce to reduce negative amt)\n",
    "1.2six of 1.3\n",
    "Pabeta of 1.2  \n",
    "1.six4 of 3\n",
    "\n",
    "Q: How long it takes to 12k iterations?\n",
    "That’s at me…See how long it takes on my computer \n",
    "vs. Inanna…fora bounded single pixel problem…\n",
    "\n",
    "'''\n",
    "\n",
    "#ordering arrays by wavelength...\n",
    "#     implot(array2, w, False, np.mean(array2))\n",
    "#     implot(hdu1_conv_scaled, w, False, np.mean(hdu1_conv_scaled)) \n",
    "#     implot(array, w, False, np.mean(array)) \n",
    "#     implot(array3, w, False, np.mean(array3)) \n",
    "\n",
    "#close but no cigar\n",
    "# cen_x = 690 # 580\n",
    "# cen_y = 440 # 370\n",
    "# del_x = 1 # 55\n",
    "# del_y = 1 #100\n",
    "\n",
    "# #perfect!\n",
    "# cen_x = 690+1 # 580\n",
    "# cen_y = 440+1 # 370\n",
    "# del_x = 1 # 55\n",
    "# del_y = 1 #100\n",
    "\n",
    "# #perfect!\n",
    "# cen_x = 690+4 # 580\n",
    "# cen_y = 440+4 # 370\n",
    "# del_x = 1 # 55\n",
    "# del_y = 1 #100\n",
    "\n",
    "# #perfect!\n",
    "cen_x = 690-1 # 580\n",
    "cen_y = 440+1 # 370\n",
    "del_x = 1 # 55\n",
    "del_y = 1 #100\n",
    "\n",
    "# #perfect!\n",
    "# cen_x = 690+25-10 # 580\n",
    "# cen_y = 440+35+10 # 370\n",
    "# del_x = 1 # 55\n",
    "# del_y = 1 #100\n",
    "\n",
    "# #perfect!\n",
    "# cen_x = 690-50 # 580\n",
    "# cen_y = 440-30 # 370\n",
    "# del_x = 1 # 55\n",
    "# del_y = 1 #100\n",
    "\n",
    "# #perfect!\n",
    "# cen_x = 690+25 # 580\n",
    "# cen_y = 440+60 # 370\n",
    "# del_x = 1 # 55\n",
    "# del_y = 1 #100\n",
    "\n",
    "# #perfect!\n",
    "# cen_x = 690-25 # 580\n",
    "# cen_y = 440+75 # 370\n",
    "# del_x = 1 # 55\n",
    "# del_y = 1 #100\n",
    "\n",
    "# #HH9? The arcy feature thing\n",
    "cutout1 = Cutout2D(array2, (cen_x, cen_y), (del_y, del_x), wcs = w.celestial)\n",
    "datacut1 = cutout1.data\n",
    "wcscut1 = cutout1.wcs \n",
    "\n",
    "cutout2 = Cutout2D(hdu1_conv_scaled, (cen_x, cen_y), (del_y, del_x), wcs = w.celestial)\n",
    "datacut2 = cutout2.data\n",
    "wcscut2 = cutout2.wcs \n",
    "\n",
    "cutout3 = Cutout2D(array, (cen_x, cen_y), (del_y, del_x), wcs = w.celestial)\n",
    "datacut3 = cutout3.data\n",
    "wcscut3 = cutout3.wcs \n",
    "\n",
    "cutout4 = Cutout2D(array3, (cen_x, cen_y), (del_y, del_x), wcs = w.celestial)\n",
    "datacut4 = cutout4.data\n",
    "wcscut4 = cutout4.wcs \n",
    "\n",
    "#plotting cutouts\n",
    "# implot(datacut1, wcscut1, False, np.mean(datacut1)) \n",
    "# implot(datacut2, wcscut2, False, np.mean(datacut2)) \n",
    "# implot(datacut3, wcscut3, False, np.mean(datacut3)) \n",
    "# implot(datacut4, wcscut4, False, np.mean(datacut4)) \n",
    "\n",
    "\n",
    "#global vars for func\n",
    "h = 6.626e-34 #SI units, J*sec\n",
    "c = 2.998e8 #SI units, m/s\n",
    "k_B = 1.38e-23 #SI, J/K\n",
    "\n",
    "#list of wavelengths for each filter being used\n",
    "lam_arr = 1e-6 * np.array([0.656, 1.26, 1.28, 1.64])\n",
    "\n",
    "#func for planck's law\n",
    "def B_lam(lam, temp=1000, const =1e5):\n",
    "    return const * 2. * h * c**2. / lam**5. * 1. / (np.exp((h * c) / (lam*k_B*temp)) - 1.)\n",
    "\n",
    "\n",
    "#continuum of filament fluxes near hh 8\n",
    "cont_flux = np.array([np.mean(datacut1), np.mean(datacut2), np.mean(datacut3), np.mean(datacut4)] )\n",
    "print(cont_flux)\n",
    "# cont_flux = np.array([np.max(datacut1), np.max(datacut2), np.max(datacut3), np.max(datacut4)] )\n",
    "\n",
    "#to convert from MJy to MJy / sr\n",
    "sr_convert = 1. / np.array([hdu3_pix**2., hdu1_pix**2., hdu2_pix**2., hdu4_pix**2.])\n",
    "#to convert from MJy to W/m^2/Hz\n",
    "jy_to_si = 1e-26 * 1e6\n",
    "#convert contflux\n",
    "cont_flux = cont_flux * jy_to_si #* sr_convert\n",
    "print(sr_convert)\n",
    "print('continuum intensity: ', c / lam_arr**2. * cont_flux)\n",
    "\n",
    "\n",
    "\n",
    "#attempting many solvers\n",
    "from scipy.optimize import newton_krylov\n",
    "from scipy.optimize import minimize\n",
    "from scipy.optimize import curve_fit\n",
    "# xin = [500, 4.105e12] #K, const...initial guesses\n",
    "xin = [5e3, 5e-24]\n",
    "popt, pcov = curve_fit(B_lam, lam_arr, c / lam_arr**2. * cont_flux, p0=xin) #solving!\n",
    "print('blackbody fit: ', popt) #output\n",
    "perr = np.sqrt(np.diag(pcov))\n",
    "print('1 sigma: ', perr)\n",
    "\n",
    "\n",
    "#plotting\n",
    "plt.figure(212) #establish new figure\n",
    "#plot to show results\n",
    "plt.scatter(1e6*lam_arr, c / lam_arr**2. * cont_flux, label = 'observation') #the data\n",
    "\n",
    "#plotting planck's law with fit params\n",
    "lam_interp = np.linspace(lam_arr[0], lam_arr[-1])\n",
    "plt.plot(1e6*lam_interp, B_lam(lam_interp, popt[0], popt[1]), linestyle='--', label = 'Blackbody Fit')\n",
    "\n",
    "#formatting\n",
    "plt.legend(loc='best')\n",
    "plt.ylim(min(c / lam_arr**2. * cont_flux) - 9e-12, max(c / lam_arr**2. * cont_flux) + 3e-11)\n",
    "plt.xlim(1e6*lam_arr[0], 1e6*lam_arr[-1])\n",
    "plt.xlabel(r'$\\lambda$ (microns)')\n",
    "plt.ylabel(r'$\\rm Intensity$ (W/m^3/sr)')\n",
    "\n",
    "\n",
    "\n",
    "#global vars for func\n",
    "R_Fe = 2.0\n",
    "R_H = 17.5\n",
    "y_arr = [0.47245, 0.77307, 0.78015, 0.85001]\n",
    "T = popt[0]\n",
    "\n",
    "#func for non-linear equation...\n",
    "def scatt_func(lam_arr, C, A_V, f_H, f_Fe):\n",
    "    return np.array([\n",
    "        (R_H * f_H + B_lam(lam_arr[0], T, C)) * y_arr[0]**A_V, \n",
    "        (R_Fe * f_Fe + B_lam(lam_arr[1], T, C)) * y_arr[1]**A_V,\n",
    "        (f_H + B_lam(lam_arr[2], T, C)) * y_arr[2]**A_V,\n",
    "        (f_Fe + B_lam(lam_arr[3], T, C)) * y_arr[3]**A_V \n",
    "        ])\n",
    "\n",
    "#attempting to fit using curve_fit\n",
    "# xin = [1e-23, 5, 1e-11, 1e-11]\n",
    "xin = [1e-23, 10, 1e-10, 1e-10]\n",
    "popt, pcov = curve_fit(scatt_func, lam_arr, c / lam_arr**2. * cont_flux, p0=xin) #solving!\n",
    "print('curve_fit attempt: ', popt)\n",
    "\n",
    "C_fit, A_V_fit, f_H_fit, f_Fe_fit = popt\n",
    "# extinc_factor = y_arr**A_V\n",
    "print(f_Fe_fit / f_H_fit)\n",
    "\n",
    "#chi^2 test...against curve_fit\n",
    "obs_intens = c / lam_arr**2. * cont_flux\n",
    "theory_intens = scatt_func(lam_arr, C_fit, A_V_fit, f_H_fit, f_Fe_fit)\n",
    "n_obs = len(obs_intens)\n",
    "chi2 = np.sum((obs_intens - theory_intens)**2.)\n",
    "print('sum(squared diffs): ', chi2)\n",
    "\n",
    "\n",
    "\n",
    "#setting up a figure to plot on these fits...\n",
    "plt.figure(213) #establish new figure\n",
    "#plot to show results\n",
    "plt.scatter(1e6*lam_arr, c / lam_arr**2. * cont_flux, label = 'Observed') #the data\n",
    "plt.scatter(1e6*lam_arr, scatt_func(lam_arr, C_fit, A_V_fit, f_H_fit, f_Fe_fit), label = 'Curve_Fit', s=20) #curve_fit method\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#redefining function to setup a system of equations equal to 0 \n",
    "def scatt_equ_solver(input_arr):\n",
    "    C, A_V, f_H, f_Fe = input_arr\n",
    "    equ_sys = c / lam_arr**2. * cont_flux - np.array([\n",
    "        (R_H * f_H + B_lam(lam_arr[0], T, C)) * y_arr[0]**A_V, \n",
    "        (R_Fe * f_Fe + B_lam(lam_arr[1], T, C)) * y_arr[1]**A_V,\n",
    "        (f_H + B_lam(lam_arr[2], T, C)) * y_arr[2]**A_V,\n",
    "        (f_Fe + B_lam(lam_arr[3], T, C)) * y_arr[3]**A_V \n",
    "        ])\n",
    "#     print(equ_sys)\n",
    "    return equ_sys\n",
    "\n",
    "#trying to solve system with non-lin solver\n",
    "from scipy.optimize import newton_krylov\n",
    "from scipy.optimize import anderson\n",
    "from scipy.optimize import broyden1\n",
    "from scipy.optimize import broyden2\n",
    "xin1 = [-1.97416054e-23,  5.23938071,  8.62153822e-11,  6.25492719e-11] #initial guess\n",
    "xin2 = [2e-23, 5.2, 9e-11, 6.3e-11] #initial guess\n",
    "xin3 = [2e-22, 2, 5e-11, 5e-11] #initial guess\n",
    "xin4 = [1e-10, 5, 1e-5, 1e-5] #initial guess\n",
    "xin5 = [2e-23, 10, 1e-12, 1e-12] #initial guess\n",
    "xin_list = [xin1, xin2, xin3, xin4, xin5]\n",
    "\n",
    "'''\n",
    "Notes from testing newton-krylov...of possible methods one can adjust\n",
    "#default: max iter can be 30-100, step can be 1e-10 to 1e-14\n",
    "#for all except cgs, can use iter of 10,000 or 100,000\\\n",
    "#for cgs can use 5000\n",
    "#that said, cgs isn't great, gmres and bicgstab seem best\n",
    "#min f_tol = 4.95e-12...maxiter with bicgstab can go up to say 100000...seems to level off at about 300 to 1000? checking...\n",
    "'''\n",
    "met = ['lgmres', 'gmres', 'bicgstab', 'cgs', 'minres']\n",
    "k = met[1]\n",
    "\n",
    "#loop testing different numbers of iterations\n",
    "iter_list = [1, 5, 10, 100, 200]\n",
    "# for i in [1, 5, 10, 100, 200]:\n",
    "i = 1000\n",
    "# for j in range(len(xin_list)):\n",
    "#     for k in met:\n",
    "#         try:\n",
    "#             print('loop: ', i, k)\n",
    "solved = newton_krylov(scatt_equ_solver, xin1, iter = i, method=k) #non-lin solver\n",
    "# solved = anderson(scatt_equ_solver, xin_list[0], f_tol=9e-12) #non-lin solver\n",
    "# solved = broyden1(scatt_equ_solver, xin_list[-1], f_tol=1e-11) #non-lin solver\n",
    "# solved = broyden2(scatt_equ_solver, xin_list[0], iter = i) #non-lin solver\n",
    "\n",
    "print('non-linear attempt: ', solved)\n",
    "\n",
    "#separating fit into diff variables...calculating a sum of squared diffs\n",
    "C_nk, A_V_nk, f_H_nk, f_Fe_nk = solved\n",
    "print('fit intensities: ', scatt_func(lam_arr, C_nk, A_V_nk, f_H_nk, f_Fe_nk))\n",
    "#calculating sum of squared diffs...against newton-krylov\n",
    "theory_intens = scatt_func(lam_arr, C_nk, A_V_nk, f_H_nk, f_Fe_nk)\n",
    "chi2 = np.sum((obs_intens - theory_intens)**2.)\n",
    "print('sum(squared diffs): ', chi2)\n",
    "\n",
    "# extinc_factor = y_arr**A_V\n",
    "print(f_Fe_nk / f_H_nk)\n",
    "#\"sanity check\" for founds on Fe/H\n",
    "\n",
    "\n",
    "#check how much time this took\n",
    "# stop = timeit.default_timer()\n",
    "# print('Time: ', stop - start)  \n",
    "\n",
    "\n",
    "#plotting non-linear fit to intensity\n",
    "# lam_interp = np.linspace(lam_arr[0], lam_arr[-1])\n",
    "# plt.scatter(1e6*lam_arr, scatt_func(lam_arr, C_nk, A_V_nk, f_H_nk, f_Fe_nk), label = 'N-K, iter='+str(i), s=20)\n",
    "#             print('success')\n",
    "#         except: \n",
    "#             print('error')\n",
    "\n",
    "#         print('RESET')\n",
    "#formatting our plot\n",
    "plt.legend(loc='best')\n",
    "plt.ylim(min(c / lam_arr**2. * cont_flux) - 9e-12, max(c / lam_arr**2. * cont_flux) + 3e-11)\n",
    "plt.xlim(1e6*lam_arr[0], 1e6*lam_arr[-1])\n",
    "plt.xlabel(r'$\\lambda$ (microns)')\n",
    "plt.ylabel(r'$\\rm Intensity$ (W/m^3/sr)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Attempting to loop through all pixels for the filament next to hh8\n",
    "'''\n",
    "\n",
    "'''\n",
    "Using \n",
    "https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.newton_krylov.html#scipy.optimize.newton_krylovfor a non linear solver…\n",
    "\n",
    "Try the algebraic solution… open up 4 images, \n",
    "put cursorover same place, see what values are…\n",
    "\n",
    "Halpha of 12*.3 (can reduce to reduce negative amt)\n",
    "1.2six of 1.3\n",
    "Pabeta of 1.2  \n",
    "1.six4 of 3\n",
    "\n",
    "Q: How long it takes to 12k iterations?\n",
    "That’s at me…See how long it takes on my computer \n",
    "vs. Inanna…fora bounded single pixel problem…\n",
    "\n",
    "'''\n",
    "\n",
    "#ordering arrays by wavelength...\n",
    "#     implot(array2, w, False, np.mean(array2))\n",
    "#     implot(hdu1_conv_scaled, w, False, np.mean(hdu1_conv_scaled)) \n",
    "#     implot(array, w, False, np.mean(array)) \n",
    "#     implot(array3, w, False, np.mean(array3)) \n",
    "\n",
    "#hh8-ish...the filament next to it that should be mostly continuum emission\n",
    "cen_x = 700\n",
    "cen_y = 500\n",
    "del_x = 200\n",
    "del_y = 360\n",
    "\n",
    "#attempting hh7\n",
    "# cen_x = 570\n",
    "# cen_y = 155\n",
    "# del_x = 100\n",
    "# del_y = 65\n",
    "# (570, 155), (65, 100)\n",
    "\n",
    "# #HH9? The arcy feature thing\n",
    "cutout1 = Cutout2D(array2, (cen_x, cen_y), (del_y, del_x), wcs = w.celestial)\n",
    "datacut1 = cutout1.data\n",
    "wcscut1 = cutout1.wcs \n",
    "\n",
    "cutout2 = Cutout2D(hdu1_conv_scaled, (cen_x, cen_y), (del_y, del_x), wcs = w.celestial)\n",
    "datacut2 = cutout2.data\n",
    "wcscut2 = cutout2.wcs \n",
    "\n",
    "cutout3 = Cutout2D(array, (cen_x, cen_y), (del_y, del_x), wcs = w.celestial)\n",
    "datacut3 = cutout3.data\n",
    "wcscut3 = cutout3.wcs \n",
    "\n",
    "cutout4 = Cutout2D(array3, (cen_x, cen_y), (del_y, del_x), wcs = w.celestial)\n",
    "datacut4 = cutout4.data\n",
    "wcscut4 = cutout4.wcs \n",
    "\n",
    "#plotting cutouts\n",
    "# implot(datacut1, wcscut1, False, np.mean(datacut1)) \n",
    "# implot(datacut2, wcscut2, False, np.mean(datacut2)) \n",
    "# implot(datacut3, wcscut3, False, np.mean(datacut3)) \n",
    "# implot(datacut4, wcscut4, False, np.mean(datacut4)) \n",
    "\n",
    "\n",
    "#global vars for func\n",
    "# h = 6.626e-34 #SI units, J*sec\n",
    "# c = 2.998e8 #SI units, m/s\n",
    "# k_B = 1.38e-23 #SI, J/K\n",
    "h = 6.626e-27 #CGS units, J*sec\n",
    "c = 2.998e10 #CGS units, m/s\n",
    "k_B = 1.38e-16 #CGS, J/K\n",
    "\n",
    "#list of wavelengths for each filter being used\n",
    "# lam_arr = 1e-6 * np.array([0.656, 1.26, 1.28, 1.64]) #in SI\n",
    "lam_arr = 1e-4 * np.array([0.656, 1.26, 1.28, 1.64]) #in CGS\n",
    "\n",
    "#to convert from MJy to MJy / sr\n",
    "sr_convert = 1. / np.array([hdu3_pix**2., hdu1_pix**2., hdu2_pix**2., hdu4_pix**2.])\n",
    "#to convert from MJy to W/m^2/Hz\n",
    "jy_to_si = 1e-26 * 1e6\n",
    "\n",
    "\n",
    "#continuum of filament fluxes near hh 8\n",
    "#if in frequency units...\n",
    "# cont_flux = np.array([datacut1 * c / (lam_arr[0])**2. * jy_to_si , \n",
    "#                       datacut2 * c / (lam_arr[1])**2. * jy_to_si , \n",
    "#                       datacut3 * c / (lam_arr[2])**2. * jy_to_si , \n",
    "#                       datacut4 * c / (lam_arr[3])**2. * jy_to_si])\n",
    "cont_flux = np.array([datacut1, \n",
    "                      datacut2, \n",
    "                      datacut3, \n",
    "                      datacut4])\n",
    "bw_arr = np.array([hdu1_bw, hdu2_bw, hdu3_bw, hdu4_bw]) * 1e-8\n",
    "# print(cont_flux)\n",
    "\n",
    "\n",
    "#func for planck's law, mks\n",
    "def B_lam(input_arr, temp=1000, const =1e-23):\n",
    "    lam, bw = input_arr\n",
    "    return const * bw * 2. * h * c**2. / lam**5. * 1. / (np.exp((h * c) / (lam*k_B*temp)) - 1.)\n",
    "\n",
    "\n",
    "#global vars for func\n",
    "R_Fe = 2.0\n",
    "R_H = 17.5\n",
    "y_arr = [0.47245, 0.77307, 0.78015, 0.85001]\n",
    "\n",
    "#func for non-linear equation...\n",
    "def scatt_func(lam_arr, C=1e-25, A_V=10, f_H=1e-20, f_Fe=1e-18):\n",
    "    return np.array([\n",
    "        (R_H * f_H + B_lam([lam_arr[0], bw_arr[0]], T, C)) * y_arr[0]**A_V, \n",
    "        (R_Fe * f_Fe + B_lam([lam_arr[1], bw_arr[1]], T, C)) * y_arr[1]**A_V,\n",
    "        (f_H + B_lam([lam_arr[2], bw_arr[2]], T, C)) * y_arr[2]**A_V,\n",
    "        (f_Fe + B_lam([lam_arr[3], bw_arr[3]], T, C)) * y_arr[3]**A_V ])\n",
    "\n",
    "\n",
    "#redefining function to setup a system of equations equal to 0 \n",
    "# def scatt_equ_solver(input_arr):\n",
    "#     C, A_V, f_H, f_Fe = input_arr\n",
    "\n",
    "#     equ_sys = pix_flux - np.array([\n",
    "#         (R_H * f_H + B_lam(lam_arr[0], T, C)) * y_arr[0]**A_V, \n",
    "#         (R_Fe * f_Fe + B_lam(lam_arr[1], T, C)) * y_arr[1]**A_V,\n",
    "#         (f_H + B_lam(lam_arr[2], T, C)) * y_arr[2]**A_V,\n",
    "#         (f_Fe + B_lam(lam_arr[3], T, C)) * y_arr[3]**A_V \n",
    "#         ])\n",
    "# #     print(equ_sys)\n",
    "#     return equ_sys\n",
    "\n",
    "\n",
    "#attempting many solvers\n",
    "from scipy.optimize import newton_krylov\n",
    "# from scipy.optimize import minimize\n",
    "from scipy.optimize import curve_fit\n",
    "# xin = [500, 4.105e12] #K, const...initial guesses\n",
    "xin = [5e3, 1e-23]\n",
    "\n",
    "#attempting to fit using curve_fit\n",
    "i_num = 5000\n",
    "xin_nk = [5e-25, 7, 1e-18, 1e-17]\n",
    "xin1 = [1e-23, 10, 1e-11, 1e-11]\n",
    "xin2 = [5e-25, 7, 1e-18, 1e-17]\n",
    "\n",
    "\n",
    "\n",
    "#array of zeros to contain fit data...\n",
    "fit_arr = [[] for x in range(cont_flux[0].shape[0] * cont_flux[0].shape[1])]\n",
    "count = 0 #count variable to index this list\n",
    "\n",
    "\n",
    "#Dans' method of constant T\n",
    "T = 4500.\n",
    "\n",
    "\n",
    "#beginning loop...\n",
    "for i in range(cont_flux[0].shape[0]):\n",
    "    for j in range(cont_flux[0].shape[1]):\n",
    "        pix_flux = [cont_flux[0][i, j], cont_flux[1][i, j], cont_flux[2][i, j], cont_flux[3][i, j]]\n",
    "        \n",
    "        #trying to get fit\n",
    "        try:\n",
    "#             popt, pcov = curve_fit(B_lam, [lam_arr, bw_arr], pix_flux, p0=xin) #solving!\n",
    "#     #         print('blackbody fit: ', popt) #output\n",
    "#             perr = np.sqrt(np.diag(pcov))\n",
    "#     #         print('1 sigma: ', perr)\n",
    "#             T = popt[0]\n",
    "\n",
    "\n",
    "            #now setting up for curve_fit\n",
    "            popt, pcov = curve_fit(scatt_func, lam_arr, pix_flux, p0=xin2)#, bounds=([0,0,0,0], [1e10,1e10,1e10,1e10])) #solving!\n",
    "    #         print('curve_fit attempt: ', popt)a\n",
    "            C_fit, A_V_fit, f_H_fit, f_Fe_fit = popt\n",
    "#             print(popt)\n",
    "#             print('fit intensities: ', scatt_func(lam_arr, C_nk, A_V_nk, f_H_nk, f_Fe_nk))\n",
    "            #chi^2 test...against curve_fit\n",
    "            obs_intens = pix_flux\n",
    "            theory_intens = scatt_func(lam_arr, C_fit, A_V_fit, f_H_fit, f_Fe_fit)\n",
    "            n_obs = len(obs_intens)\n",
    "            chi2 = np.sum((obs_intens - theory_intens)**2.)\n",
    "            print('non-linear attempt, curve fit: ', [ C_fit, A_V_fit, f_H_fit, f_Fe_fit])\n",
    "            print('fit intensities, curve fit: ', scatt_func(lam_arr,  C_fit, A_V_fit, f_H_fit, f_Fe_fit))\n",
    "            print('sum(squared diffs, curve fit): ', chi2)\n",
    "\n",
    "            #saving results\n",
    "            fit_arr[count] = [i, j, chi2, theory_intens, T, C_fit, A_V_fit, f_H_fit, f_Fe_fit]\n",
    "        \n",
    "        except: \n",
    "            try:\n",
    "                solved = newton_krylov(scatt_equ_solver, xin_nk) #non-lin solver\n",
    "                print('non-linear attempt: ', solved)\n",
    "                #separating fit into diff variables...calculating a sum of squared diffs\n",
    "                C_nk, A_V_nk, f_H_nk, f_Fe_nk = solved\n",
    "                print('fit intensities: ', scatt_func(lam_arr, C_nk, A_V_nk, f_H_nk, f_Fe_nk))\n",
    "                #calculating sum of squared diffs...against newton-krylov\n",
    "                theory_intens = scatt_func(lam_arr, C_nk, A_V_nk, f_H_nk, f_Fe_nk)\n",
    "                chi2 = np.sum((obs_intens - theory_intens)**2.)\n",
    "                print('sum(squared diffs): ', chi2)\n",
    "\n",
    "                #saving results\n",
    "                fit_arr[count] = [i, j, chi2, theory_intens, T, C_fit, A_V_fit, f_H_fit, f_Fe_fit]\n",
    "            \n",
    "            except Exception as e:\n",
    "                print('type is:', e.__class__.__name__)\n",
    "                fit_arr[count] = [i, j, -1, [-1, -1, -1, -1], -1, -1, -1, -1, -1]\n",
    "            \n",
    "\n",
    "        \n",
    "\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#this cell tries to plot the solutions to the equation's parameters\n",
    "\n",
    "# print(datacut1)\n",
    "# print(model_arr_lam2)\n",
    "\n",
    "#hh8-ish...the filament next to it that should be mostly continuum emission\n",
    "cen_x = 700\n",
    "cen_y = 500\n",
    "del_x = 200\n",
    "del_y = 360\n",
    "\n",
    "#attempting hh7\n",
    "# cen_x = 570\n",
    "# cen_y = 155\n",
    "# del_x = 100\n",
    "# del_y = 65\n",
    "# (570, 155), (65, 100)\n",
    "\n",
    "# #HH9? The arcy feature thing\n",
    "cutout1 = Cutout2D(array2, (cen_x, cen_y), (del_y, del_x), wcs = w.celestial)\n",
    "datacut1 = cutout1.data\n",
    "wcscut1 = cutout1.wcs \n",
    "\n",
    "cutout2 = Cutout2D(hdu1_conv_scaled, (cen_x, cen_y), (del_y, del_x), wcs = w.celestial)\n",
    "datacut2 = cutout2.data\n",
    "wcscut2 = cutout2.wcs \n",
    "\n",
    "cutout3 = Cutout2D(array, (cen_x, cen_y), (del_y, del_x), wcs = w.celestial)\n",
    "datacut3 = cutout3.data\n",
    "wcscut3 = cutout3.wcs \n",
    "\n",
    "cutout4 = Cutout2D(array3, (cen_x, cen_y), (del_y, del_x), wcs = w.celestial)\n",
    "datacut4 = cutout4.data\n",
    "wcscut4 = cutout4.wcs \n",
    "\n",
    "#plotting cutouts of actual data\n",
    "implot(datacut1, wcscut1, False, np.mean(datacut1)) \n",
    "plt.title('H Alpha')\n",
    "implot(datacut2, wcscut2, False, np.mean(datacut2)) \n",
    "plt.title('1.26 microns')\n",
    "implot(datacut3, wcscut3, False, np.mean(datacut3)) \n",
    "plt.title('1.28 microns')\n",
    "implot(datacut4, wcscut4, False, np.mean(datacut4)) \n",
    "plt.title('1.64 microns')\n",
    "\n",
    "\n",
    "#planning to save file data...\n",
    "#format: fit_arr[count] = [i, j, chi2, theory_intens, T, C_fit, A_V_fit, f_H_fit, f_Fe_fit]\n",
    "#header=[\"i\", \"j\", \"sumsq\", \"Intensity(W/m^3/sr)\" ,\"Temp(K)\", \"C\", \"A_V\", \"f_H\", \"f_Fe\"]\n",
    "# my_data = np.savetxt('fitting_box16_bad.txt', fit_arr, delimiter=',')\n",
    "\n",
    "#setting up array of model fluxes\n",
    "model_arr_lam1 = np.zeros_like(cont_flux[0])\n",
    "model_arr_lam2 = np.zeros_like(cont_flux[0])\n",
    "model_arr_lam3 = np.zeros_like(cont_flux[0])\n",
    "model_arr_lam4 = np.zeros_like(cont_flux[0])\n",
    "f_H_arr = np.zeros_like(cont_flux[0])\n",
    "f_Fe_arr = np.zeros_like(cont_flux[0])\n",
    "C_arr = np.zeros_like(cont_flux[0])\n",
    "A_V_arr = np.zeros_like(cont_flux[0])\n",
    "\n",
    "\n",
    "ind = 3 # used for picking type of image to plot\n",
    "#reorganizing data in 2d array to be plotted\n",
    "for line in fit_arr:\n",
    "    #indices\n",
    "    i = line[0]\n",
    "    j = line[1]\n",
    "    \n",
    "    #storing model intensity data\n",
    "#     try:\n",
    "#     model_arr_lam1[i][j] = line[ind][0]\n",
    "#     model_arr_lam2[i][j] = line[ind][1]\n",
    "#     model_arr_lam3[i][j] = line[ind][2]\n",
    "#     model_arr_lam4[i][j] = line[ind][3]\n",
    "    \n",
    "    C_arr[i][j] = line[-4]\n",
    "    A_V_arr[i][j] = line[-3]\n",
    "    f_H_arr[i][j] = line[-2]\n",
    "    f_Fe_arr[i][j] = line[-1]\n",
    "    \n",
    "#     except:\n",
    "        \n",
    "        \n",
    "        \n",
    "#plotting\n",
    "# implot(model_arr_lam1, w, True, np.max(model_arr_lam1)/5.) \n",
    "# implot(model_arr_lam2, w, True, np.max(model_arr_lam1)/5.) \n",
    "# implot(model_arr_lam3, w, True, np.max(model_arr_lam1)/5.) \n",
    "# implot(model_arr_lam4, w, True, np.max(model_arr_lam1)/40.) \n",
    "\n",
    "print(np.max(C_arr), np.max(A_V_arr), np.max(f_H_arr), np.max(f_Fe_arr))\n",
    "print(C_arr)\n",
    "print(A_V_arr)\n",
    "sys.exit\n",
    "# implot(C_arr, w, True, np.max(C_arr)/1e10) #for \"perfect fit\" curve_fit\n",
    "implot(C_arr, w, True, np.max(C_arr)/1e6) #for positive valued curve_fit\n",
    "plt.title('C')\n",
    "# implot(A_V_arr, w, True, np.max(A_V_arr)) #for \"perfect fit\" curve_fit\n",
    "implot(A_V_arr, w, True, np.max(A_V_arr)/6e1) #for positive valued curve_fit\n",
    "plt.title('A_V')\n",
    "# implot(f_H_arr, w, True, np.max(f_H_arr)/1e9) #for \"perfect fit\" curve_fit\n",
    "implot(f_H_arr, w, True, np.max(f_H_arr)/1e8) #for positive valued curve_fit\n",
    "plt.title('f_H')\n",
    "# implot(f_Fe_arr, w, True, np.max(f_Fe_arr)/5e8) #for \"perfect fit\" curve_fit\n",
    "implot(f_Fe_arr, w, True, np.max(f_Fe_arr)/1e8) #for positive valued curve_fit\n",
    "plt.title('f_Fe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Attempting to loop through all pixels, for hh7 region\n",
    "'''\n",
    "\n",
    "'''\n",
    "Using \n",
    "https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.newton_krylov.html#scipy.optimize.newton_krylovfor a non linear solver…\n",
    "\n",
    "Try the algebraic solution… open up 4 images, \n",
    "put cursorover same place, see what values are…\n",
    "\n",
    "Halpha of 12*.3 (can reduce to reduce negative amt)\n",
    "1.2six of 1.3\n",
    "Pabeta of 1.2  \n",
    "1.six4 of 3\n",
    "\n",
    "Q: How long it takes to 12k iterations?\n",
    "That’s at me…See how long it takes on my computer \n",
    "vs. Inanna…fora bounded single pixel problem…\n",
    "\n",
    "'''\n",
    "\n",
    "#ordering arrays by wavelength...\n",
    "#     implot(array2, w, False, np.mean(array2))\n",
    "#     implot(hdu1_conv_scaled, w, False, np.mean(hdu1_conv_scaled)) \n",
    "#     implot(array, w, False, np.mean(array)) \n",
    "#     implot(array3, w, False, np.mean(array3)) \n",
    "\n",
    "#hh8-ish...the filament next to it that should be mostly continuum emission\n",
    "# cen_x = 700\n",
    "# cen_y = 500\n",
    "# del_x = 200\n",
    "# del_y = 360\n",
    "\n",
    "#attempting hh7\n",
    "cen_x = 570\n",
    "cen_y = 155\n",
    "del_x = 100\n",
    "del_y = 65\n",
    "# (570, 155), (65, 100)\n",
    "\n",
    "# #HH9? The arcy feature thing\n",
    "cutout1 = Cutout2D(array2, (cen_x, cen_y), (del_y, del_x), wcs = w.celestial)\n",
    "datacut1 = cutout1.data\n",
    "wcscut1 = cutout1.wcs \n",
    "\n",
    "cutout2 = Cutout2D(hdu1_conv_scaled, (cen_x, cen_y), (del_y, del_x), wcs = w.celestial)\n",
    "datacut2 = cutout2.data\n",
    "wcscut2 = cutout2.wcs \n",
    "\n",
    "cutout3 = Cutout2D(array, (cen_x, cen_y), (del_y, del_x), wcs = w.celestial)\n",
    "datacut3 = cutout3.data\n",
    "wcscut3 = cutout3.wcs \n",
    "\n",
    "cutout4 = Cutout2D(array3, (cen_x, cen_y), (del_y, del_x), wcs = w.celestial)\n",
    "datacut4 = cutout4.data\n",
    "wcscut4 = cutout4.wcs \n",
    "\n",
    "#plotting cutouts\n",
    "# implot(datacut1, wcscut1, False, np.mean(datacut1)) \n",
    "# implot(datacut2, wcscut2, False, np.mean(datacut2)) \n",
    "# implot(datacut3, wcscut3, False, np.mean(datacut3)) \n",
    "# implot(datacut4, wcscut4, False, np.mean(datacut4)) \n",
    "\n",
    "\n",
    "#global vars for func\n",
    "h = 6.626e-27 #CGS units, J*sec\n",
    "c = 2.998e10 #CGS units, m/s\n",
    "k_B = 1.38e-16 #CGS, J/K\n",
    "\n",
    "#list of wavelengths for each filter being used\n",
    "# lam_arr = 1e-6 * np.array([0.656, 1.26, 1.28, 1.64]) #in SI\n",
    "lam_arr = 1e-4 * np.array([0.656, 1.26, 1.28, 1.64]) #in CGS\n",
    "\n",
    "#to convert from MJy to MJy / sr\n",
    "sr_convert = 1. / np.array([hdu3_pix**2., hdu1_pix**2., hdu2_pix**2., hdu4_pix**2.])\n",
    "#to convert from MJy to W/m^2/Hz\n",
    "jy_to_si = 1e-26 * 1e6\n",
    "\n",
    "\n",
    "#continuum of filament fluxes near hh 8\n",
    "#if in frequency units...\n",
    "# cont_flux = np.array([datacut1 * c / (lam_arr[0])**2. * jy_to_si , \n",
    "#                       datacut2 * c / (lam_arr[1])**2. * jy_to_si , \n",
    "#                       datacut3 * c / (lam_arr[2])**2. * jy_to_si , \n",
    "#                       datacut4 * c / (lam_arr[3])**2. * jy_to_si])\n",
    "cont_flux2 = np.array([datacut1, \n",
    "                      datacut2, \n",
    "                      datacut3, \n",
    "                      datacut4])\n",
    "bw_arr = np.array([hdu1_bw, hdu2_bw, hdu3_bw, hdu4_bw]) * 1e-8\n",
    "# print(cont_flux)\n",
    "\n",
    "\n",
    "#func for planck's law, mks\n",
    "def B_lam(input_arr, temp=1000, const =1e-23):\n",
    "    lam, bw = input_arr\n",
    "    return const * bw * 2. * h * c**2. / lam**5. * 1. / (np.exp((h * c) / (lam*k_B*temp)) - 1.)\n",
    "\n",
    "\n",
    "#global vars for func\n",
    "R_Fe = 2.0\n",
    "R_H = 17.5\n",
    "y_arr = [0.47245, 0.77307, 0.78015, 0.85001]\n",
    "\n",
    "#for method curve_fit...func for non-linear equation...\n",
    "def scatt_func(lam_arr, C, A_V_fit, f_H, f_Fe):\n",
    "    return np.array([\n",
    "        (R_H * f_H + B_lam([lam_arr[0], bw_arr[0]], T, C)) * y_arr[0]**A_V_fit, \n",
    "        (R_Fe * f_Fe + B_lam([lam_arr[1], bw_arr[1]], T, C)) * y_arr[1]**A_V_fit,\n",
    "        (f_H + B_lam([lam_arr[2], bw_arr[2]], T, C)) * y_arr[2]**A_V_fit,\n",
    "        (f_Fe + B_lam([lam_arr[3], bw_arr[3]], T, C)) * y_arr[3]**A_V_fit ])\n",
    "\n",
    "#for method root\n",
    "def scatt_func_root(C, A_V_fit, f_H, f_Fe):\n",
    "    return np.array([\n",
    "        (R_H * f_H + B_lam(lam_arr[0], T, C)) * y_arr[0]**A_V_fit, \n",
    "        (R_Fe * f_Fe + B_lam(lam_arr[1], T, C)) * y_arr[1]**A_V_fit,\n",
    "        (f_H + B_lam(lam_arr[2], T, C)) * y_arr[2]**A_V_fit,\n",
    "        (f_Fe + B_lam(lam_arr[3], T, C)) * y_arr[3]**A_V_fit ])\n",
    "\n",
    "#for method newton-krylov redefining function to setup a system of equations equal to 0 \n",
    "def scatt_equ_solver(input_arr):\n",
    "    C, A_V_fit, f_H, f_Fe = input_arr\n",
    "\n",
    "    equ_sys = pix_flux - np.array([\n",
    "        (R_H * f_H + B_lam([lam_arr[0], bw_arr[0]], T, C)) * y_arr[0]**A_V_fit, \n",
    "        (R_Fe * f_Fe + B_lam([lam_arr[1], bw_arr[1]], T, C)) * y_arr[1]**A_V_fit,\n",
    "        (f_H + B_lam([lam_arr[2], bw_arr[2]], T, C)) * y_arr[2]**A_V_fit,\n",
    "        (f_Fe + B_lam([lam_arr[3], bw_arr[3]], T, C)) * y_arr[3]**A_V_fit \n",
    "        ])\n",
    "    return equ_sys\n",
    "\n",
    "\n",
    "#attempting many solvers\n",
    "from scipy.optimize import newton_krylov\n",
    "# from scipy.optimize import minimize\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.optimize import root\n",
    "from scipy.optimize import fmin_tnc\n",
    "# xin = [500, 4.105e12] #K, const...initial guesses\n",
    "xin = [5e3, 1e-23]\n",
    "\n",
    "#different initial guesses\n",
    "i_num = 500\n",
    "xin_root = [5.63120728e-28, 1., 1e-18, 1e-17]\n",
    "xin_nk = np.array([5.63120728e-25, 7., 1e-18, 1e-17])\n",
    "xin1 = [1e-28, 10, 1e-18, 1e-17]\n",
    "xin2 = [5e-25, 7, 1e-18, 1e-17]\n",
    "# xin2 = [0. ,0., 0., 0.]\n",
    "\n",
    "\n",
    "\n",
    "#array of zeros to contain fit data...\n",
    "fit_arr2 = [[] for x in range(cont_flux2[0].shape[0] * cont_flux2[0].shape[1])]\n",
    "count = 0 #count variable to index this list\n",
    "\n",
    "\n",
    "#trying Dan's method of setting temperature...\n",
    "T = 4500.\n",
    "\n",
    "#beginning loop...\n",
    "for i in range(cont_flux2[0].shape[0]):\n",
    "    for j in range(cont_flux2[0].shape[1]):\n",
    "        pix_flux = np.array([cont_flux2[0][i, j], cont_flux2[1][i, j], cont_flux2[2][i, j], cont_flux2[3][i, j]])\n",
    "#         sigma_arr = [cont_flux[0][i, j]/1e5, cont_flux[1][i, j]/1e5, cont_flux[2][i, j]/1e5, cont_flux[3][i, j]/1e5]\n",
    "        \n",
    "        #trying to get fit\n",
    "        try:\n",
    "#             popt, pcov = curve_fit(B_lam, [lam_arr, bw_arr], pix_flux, p0=xin) #solving!\n",
    "#     #         print('blackbody fit: ', popt) #output\n",
    "#             perr = np.sqrt(np.diag(pcov))\n",
    "#     #         print('1 sigma: ', perr)\n",
    "#             T = popt[0]\n",
    "\n",
    "\n",
    "#             #now setting up for curve_fit\n",
    "            popt, pcov = curve_fit(scatt_func, lam_arr, pix_flux, p0=xin2)#, bounds=([0,0,0,0], [np.inf,np.inf,np.inf,np.inf])) #solving!\n",
    "    #         print('curve_fit attempt: ', popt)a\n",
    "            C_fit, A_V_fit, f_H_fit, f_Fe_fit = popt\n",
    "#             print(popt)\n",
    "#             print('fit intensities: ', scatt_func(lam_arr, C_nk, A_V_nk, f_H_nk, f_Fe_nk))\n",
    "            #chi^2 test...against curve_fit\n",
    "            obs_intens = pix_flux\n",
    "            theory_intens = scatt_func(lam_arr, C_fit, A_V_fit, f_H_fit, f_Fe_fit)\n",
    "            n_obs = len(obs_intens)\n",
    "            chi2 = np.sum((obs_intens - theory_intens)**2.)\n",
    "            print('non-linear attempt, curve fit: ', [ C_fit, A_V_fit, f_H_fit, f_Fe_fit])\n",
    "            print('fit intensities, curve fit: ', scatt_func(lam_arr,  C_fit, A_V_fit, f_H_fit, f_Fe_fit))\n",
    "            print('sum(squared diffs, curve fit): ', chi2)\n",
    "\n",
    "            #saving results\n",
    "            fit_arr2[count] = [i, j, chi2, theory_intens, T, C_fit, A_V_fit, f_H_fit, f_Fe_fit]\n",
    "\n",
    "\n",
    "\n",
    "           #setting up for newton-krylov\n",
    "#             xin_nk = popt  #if performing newton-krylov method and feeding using curve fit\n",
    "\n",
    "#             solved = newton_krylov(scatt_equ_solver, xin_nk)#, f_tol=1e-14, method='gmres') #non-lin solver. ftol 1E-8ish with gmres\n",
    "#             print('non-linear attempt, NK: ', solved)\n",
    "#             #separating fit into diff variables...calculating a sum of squared diffs\n",
    "#             C_nk, A_V_fitnk, f_H_nk, f_Fe_nk = solved\n",
    "#             print('fit intensities, NK: ', scatt_func(lam_arr, C_nk, A_V_fitnk, f_H_nk, f_Fe_nk))\n",
    "#             #calculating sum of squared diffs...against newton-krylov\n",
    "#             obs_intens = pix_flux\n",
    "#             theory_intens = scatt_func(lam_arr, C_nk, A_V_fitnk, f_H_nk, f_Fe_nk)\n",
    "#             chi2 = np.sum((pix_flux - theory_intens)**2.)\n",
    "#             print('sum(squared diffs, NK): ', chi2)\n",
    "\n",
    "#             #saving results\n",
    "#             fit_arr2[count] = [i, j, chi2, theory_intens, T, C_nk, A_V_fitnk, f_H_nk, f_Fe_nk]\n",
    "\n",
    "\n",
    "\n",
    "            #if performing fmin_tnc, a type of newton's method minimization\n",
    "#             solved = fmin_tnc(scatt_equ_solver, xin_nk, bounds=([(0,np.inf),(0,np.inf),(0,np.inf),(0,np.inf)]), approx_grad=True)#,method='gmres') #non-lin solver. ftol 1E-8ish with gmres\n",
    "#             print('non-linear attempt, tnc: ', solved)\n",
    "#             #separating fit into diff variables...calculating a sum of squared diffs\n",
    "#             C_tnc, A_V_fittnc, f_H_tnc, f_Fe_tnc = solved\n",
    "#             print('fit intensities, tnc: ', scatt_func(lam_arr, C_tnc, A_V_fittnc, f_H_tnc, f_Fe_tnc))\n",
    "#             #calculating sum of squared diffs...against newton-krylov\n",
    "#             obs_intens = pix_flux\n",
    "#             theory_intens = scatt_func(lam_arr, C_tnc, A_V_fittnc, f_H_tnc, f_Fe_tnc)\n",
    "#             chi2 = np.sum((pix_flux - theory_intens)**2.)\n",
    "#             print('sum(squared diffs, tnc): ', chi2)\n",
    "\n",
    "#             #saving results\n",
    "#             fit_arr2[count] = [i, j, chi2, theory_intens, T, C_tnc, A_V_fittnc, f_H_tnc, f_Fe_tnc]\n",
    "\n",
    "\n",
    "\n",
    "            #using the generic root method in scipy.optimize\n",
    "#             solved = root(scatt_func_root, xin_root, method='lm') #non-lin solver. ftol 1E-8ish with gmres\n",
    "#             print('non-linear attempt, root: ', solved['x'])\n",
    "#             #separating fit into diff variables...calculating a sum of squared diffs\n",
    "#             C_root, A_V_fitroot, f_H_root, f_Fe_root = solved['x']\n",
    "#             print('fit intensities, root: ', scatt_func(lam_arr, C_root, A_V_fitroot, f_H_root, f_Fe_root))\n",
    "#             #calculating sum of squared diffs...against newton-krylov\n",
    "#             obs_intens = pix_flux\n",
    "#             theory_intens = scatt_func(lam_arr, C_root, A_V_fitroot, f_H_root, f_Fe_root)\n",
    "#             chi2 = np.sum((pix_flux - theory_intens)**2.)\n",
    "#             print('sum(squared diffs, root): ', chi2)\n",
    "\n",
    "            \n",
    "            \n",
    "#             #saving results\n",
    "#             fit_arr2[count] = [i, j, chi2, theory_intens, T, C_root, A_V_fitroot, f_H_root, f_Fe_root]\n",
    "\n",
    "\n",
    "        #should try newton krylov as backup...\n",
    "        except Exception as e: \n",
    "            try:\n",
    "                solved = newton_krylov(scatt_equ_solver, xin_nk)#, f_tol=1e-14, method='gmres') #non-lin solver. ftol 1E-8ish with gmres\n",
    "                print('non-linear attempt, NK: ', solved)\n",
    "                #separating fit into diff variables...calculating a sum of squared diffs\n",
    "                C_nk, A_V_fitnk, f_H_nk, f_Fe_nk = solved\n",
    "                print('fit intensities, NK: ', scatt_func(lam_arr, C_nk, A_V_fitnk, f_H_nk, f_Fe_nk))\n",
    "                #calculating sum of squared diffs...against newton-krylov\n",
    "                obs_intens = pix_flux\n",
    "                theory_intens = scatt_func(lam_arr, C_nk, A_V_fitnk, f_H_nk, f_Fe_nk)\n",
    "                chi2 = np.sum((pix_flux - theory_intens)**2.)\n",
    "                print('sum(squared diffs, NK): ', chi2)\n",
    "\n",
    "                #saving results\n",
    "                fit_arr2[count] = [i, j, chi2, theory_intens, T, C_nk, A_V_fitnk, f_H_nk, f_Fe_nk]\n",
    "                \n",
    "            except Exception as e:\n",
    "                print('type is:', e.__class__.__name__)\n",
    "                fit_arr2[count] = [i, j, -1, [-1, -1, -1, -1], -1, -1, -1, -1, -1]\n",
    "            \n",
    "\n",
    "        \n",
    "\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#plotting solution found for hh7 region pixels\n",
    "\n",
    "# print(datacut1)\n",
    "# print(model_arr_lam2)\n",
    "\n",
    "#attempting hh7\n",
    "cen_x = 570\n",
    "cen_y = 155\n",
    "del_x = 100\n",
    "del_y = 65\n",
    "# (570, 155), (65, 100)\n",
    "\n",
    "# #HH9? The arcy feature thing\n",
    "cutout1 = Cutout2D(array2, (cen_x, cen_y), (del_y, del_x), wcs = w.celestial)\n",
    "datacut1 = cutout1.data\n",
    "wcscut1 = cutout1.wcs \n",
    "\n",
    "cutout2 = Cutout2D(hdu1_conv_scaled, (cen_x, cen_y), (del_y, del_x), wcs = w.celestial)\n",
    "datacut2 = cutout2.data\n",
    "wcscut2 = cutout2.wcs \n",
    "\n",
    "cutout3 = Cutout2D(array, (cen_x, cen_y), (del_y, del_x), wcs = w.celestial)\n",
    "datacut3 = cutout3.data\n",
    "wcscut3 = cutout3.wcs \n",
    "\n",
    "cutout4 = Cutout2D(array3, (cen_x, cen_y), (del_y, del_x), wcs = w.celestial)\n",
    "datacut4 = cutout4.data\n",
    "wcscut4 = cutout4.wcs \n",
    "\n",
    "#plotting cutouts of actual data\n",
    "implot(datacut1, wcscut1, False, np.mean(datacut1)) \n",
    "plt.title('H Alpha')\n",
    "implot(datacut2, wcscut2, False, np.mean(datacut2)) \n",
    "plt.title('1.26 microns')\n",
    "implot(datacut3, wcscut3, False, np.mean(datacut3)) \n",
    "plt.title('1.28 microns')\n",
    "implot(datacut4, wcscut4, False, np.mean(datacut4)) \n",
    "plt.title('1.64 microns')\n",
    "\n",
    "\n",
    "#planning to save file data...\n",
    "#format: fit_arr[count] = [i, j, chi2, theory_intens, T, C_fit, A_V_fit, f_H_fit, f_Fe_fit]\n",
    "#header=[\"i\", \"j\", \"sumsq\", \"Intensity(W/m^3/sr)\" ,\"Temp(K)\", \"C\", \"A_V\", \"f_H\", \"f_Fe\"]\n",
    "# my_data = np.savetxt('fitting_box16_bad.txt', fit_arr, delimiter=',')\n",
    "\n",
    "#setting up array of model fluxes\n",
    "# model_arr_lam1 = np.zeros_like(cont_flux2[0])\n",
    "# model_arr_lam2 = np.zeros_like(cont_flux2[0])\n",
    "# model_arr_lam3 = np.zeros_like(cont_flux2[0])\n",
    "# model_arr_lam4 = np.zeros_like(cont_flux2[0])\n",
    "f_H_arr = np.zeros_like(cont_flux2[0])\n",
    "f_Fe_arr = np.zeros_like(cont_flux2[0])\n",
    "C_arr = np.zeros_like(cont_flux2[0])\n",
    "A_V_arr = np.zeros_like(cont_flux2[0])\n",
    "\n",
    "\n",
    "ind = 3 # used for picking type of image to plot\n",
    "#reorganizing data in 2d array to be plotted\n",
    "\n",
    "for line in fit_arr2:\n",
    "\n",
    "    #indices\n",
    "    i = line[0]\n",
    "    j = line[1]\n",
    "\n",
    "    #storing model intensity data\n",
    "#     try:\n",
    "#     model_arr_lam1[i][j] = line[ind][0]\n",
    "#     model_arr_lam2[i][j] = line[ind][1]\n",
    "#     model_arr_lam3[i][j] = line[ind][2]\n",
    "#     model_arr_lam4[i][j] = line[ind][3]\n",
    "\n",
    "    C_arr[i][j] = line[-4]\n",
    "    A_V_arr[i][j] = line[-3]\n",
    "    f_H_arr[i][j] = line[-2]\n",
    "    f_Fe_arr[i][j] = line[-1]\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "#plotting\n",
    "# implot(model_arr_lam1, w, True, np.max(model_arr_lam1)/5.) \n",
    "# implot(model_arr_lam2, w, True, np.max(model_arr_lam1)/5.) \n",
    "# implot(model_arr_lam3, w, True, np.max(model_arr_lam1)/5.) \n",
    "# implot(model_arr_lam4, w, True, np.max(model_arr_lam1)/40.) \n",
    "\n",
    "print(np.max(C_arr), np.max(A_V_arr), np.max(f_H_arr), np.max(f_Fe_arr))\n",
    "print(C_arr)\n",
    "print(A_V_arr)\n",
    "# implot(C_arr, w, True, np.max(C_arr)/1e10) #for \"perfect fit\" curve_fit\n",
    "implot(C_arr, w, True, np.max(C_arr)/2e3) #for positive valued curve_fit\n",
    "plt.title('C')\n",
    "# implot(A_V_arr, w, True, np.max(A_V_arr)) #for \"perfect fit\" curve_fit\n",
    "implot(A_V_arr, w, True, np.max(A_V_arr)/4e1) #for positive valued curve_fit\n",
    "plt.title('A_V')\n",
    "# implot(f_H_arr, w, True, np.max(f_H_arr)/1e9) #for \"perfect fit\" curve_fit\n",
    "implot(f_H_arr, w, True, np.max(f_H_arr)/7e1) #for positive valued curve_fit\n",
    "plt.title('f_H')\n",
    "# implot(f_Fe_arr, w, True, np.max(f_Fe_arr)/5e6) #for \"perfect fit\" curve_fit\n",
    "implot(f_Fe_arr, w, True, np.max(f_Fe_arr)/7e1) #for positive valued curve_fit\n",
    "plt.title('f_Fe')\n",
    "# implot(model_arr_lam3, w, True, np.max(model_arr_lam1)/5.) \n",
    "# implot(model_arr_lam4, w, True, np.max(model_arr_lam1)/40.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reminder on how to save files...\n",
    "path = 'data_arrs/'\n",
    "\n",
    "# np.savetxt(path + 'f1.txt', array2)\n",
    "# np.savetxt(path + 'f2.txt', hdu1_conv_scaled)\n",
    "# np.savetxt(path + 'f3.txt', array)\n",
    "# np.savetxt(path + 'f4.txt', array3)\n",
    "\n",
    "np.savetxt(path + 'hh7_C.txt', C_arr)\n",
    "np.savetxt(path + 'hh7_av.txt', A_V_arr)\n",
    "np.savetxt(path + 'hh7_fh.txt', f_H_arr)\n",
    "np.savetxt(path + 'hh7_ffe.txt', f_Fe_arr)\n",
    "\n",
    "\n",
    "# def arr_to_tab(data_arr):\n",
    "#     return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Attempting to loop through all pixels, for whole hh7-11 region\n",
    "'''\n",
    "\n",
    "'''\n",
    "Using \n",
    "https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.newton_krylov.html#scipy.optimize.newton_krylovfor a non linear solver…\n",
    "\n",
    "Try the algebraic solution… open up 4 images, \n",
    "put cursorover same place, see what values are…\n",
    "\n",
    "Halpha of 12*.3 (can reduce to reduce negative amt)\n",
    "1.2six of 1.3\n",
    "Pabeta of 1.2  \n",
    "1.six4 of 3\n",
    "\n",
    "Q: How long it takes to 12k iterations?\n",
    "That’s at me…See how long it takes on my computer \n",
    "vs. Inanna…fora bounded single pixel problem…\n",
    "\n",
    "'''\n",
    "\n",
    "#ordering arrays by wavelength...\n",
    "#     implot(array2, w, False, np.mean(array2))\n",
    "#     implot(hdu1_conv_scaled, w, False, np.mean(hdu1_conv_scaled)) \n",
    "#     implot(array, w, False, np.mean(array)) \n",
    "#     implot(array3, w, False, np.mean(array3)) \n",
    "\n",
    "#plotting cutouts\n",
    "datacut1 = array2\n",
    "datacut2 = hdu1_conv_scaled\n",
    "datacut3 = array\n",
    "datacut4 = array3\n",
    "\n",
    "wcscut1 = w\n",
    "wcscut2 = w\n",
    "wcscut3 = w\n",
    "wcscut4 = w\n",
    "\n",
    "# implot(datacut1, wcscut1, False, np.mean(datacut1)) \n",
    "# implot(datacut2, wcscut2, False, np.mean(datacut2)) \n",
    "# implot(datacut3, wcscut3, False, np.mean(datacut3)) \n",
    "# implot(datacut4, wcscut4, False, np.mean(datacut4)) \n",
    "\n",
    "\n",
    "#global vars for func\n",
    "h = 6.626e-27 #CGS units, J*sec\n",
    "c = 2.998e10 #CGS units, m/s\n",
    "k_B = 1.38e-16 #CGS, J/K\n",
    "\n",
    "#list of wavelengths for each filter being used\n",
    "# lam_arr = 1e-6 * np.array([0.656, 1.26, 1.28, 1.64]) #in SI\n",
    "lam_arr = 1e-4 * np.array([0.656, 1.26, 1.28, 1.64]) #in CGS\n",
    "\n",
    "#to convert from MJy to MJy / sr\n",
    "sr_convert = 1. / np.array([hdu3_pix**2., hdu1_pix**2., hdu2_pix**2., hdu4_pix**2.])\n",
    "#to convert from MJy to W/m^2/Hz\n",
    "jy_to_si = 1e-26 * 1e6\n",
    "\n",
    "\n",
    "#continuum of filament fluxes near hh 8\n",
    "#if in frequency units...\n",
    "# cont_flux = np.array([datacut1 * c / (lam_arr[0])**2. * jy_to_si , \n",
    "#                       datacut2 * c / (lam_arr[1])**2. * jy_to_si , \n",
    "#                       datacut3 * c / (lam_arr[2])**2. * jy_to_si , \n",
    "#                       datacut4 * c / (lam_arr[3])**2. * jy_to_si])\n",
    "cont_flux2 = np.array([datacut1, \n",
    "                      datacut2, \n",
    "                      datacut3, \n",
    "                      datacut4])\n",
    "bw_arr = np.array([hdu1_bw, hdu2_bw, hdu3_bw, hdu4_bw]) * 1e-8\n",
    "# print(cont_flux)\n",
    "\n",
    "\n",
    "#func for planck's law, cgs\n",
    "#https://yceo.yale.edu/sites/default/files/files/ComputingThePlanckFunction.pdf\n",
    "def B_lam(input_arr, temp=1000, const =1e-23):\n",
    "    lam, bw = input_arr\n",
    "    return const * bw * 2. * h * c**2. / lam**5. * 1. / (np.exp((h * c) / (lam*k_B*temp)) - 1.)\n",
    "\n",
    "\n",
    "#global vars for func\n",
    "R_Fe = 2.0\n",
    "R_H = 17.5\n",
    "y_arr = [0.47245, 0.77307, 0.78015, 0.85001]\n",
    "\n",
    "#for method curve_fit...func for non-linear equation...\n",
    "def scatt_func(lam_arr, C, A_V_fit, f_H, f_Fe):\n",
    "    return np.array([\n",
    "        (R_H * f_H + B_lam([lam_arr[0], bw_arr[0]], T, C)) * y_arr[0]**A_V_fit, \n",
    "        (R_Fe * f_Fe + B_lam([lam_arr[1], bw_arr[1]], T, C)) * y_arr[1]**A_V_fit,\n",
    "        (f_H + B_lam([lam_arr[2], bw_arr[2]], T, C)) * y_arr[2]**A_V_fit,\n",
    "        (f_Fe + B_lam([lam_arr[3], bw_arr[3]], T, C)) * y_arr[3]**A_V_fit ])\n",
    "\n",
    "#for method root\n",
    "def scatt_func_root(C, A_V_fit, f_H, f_Fe):\n",
    "    return np.array([\n",
    "        (R_H * f_H + B_lam(lam_arr[0], T, C)) * y_arr[0]**A_V_fit, \n",
    "        (R_Fe * f_Fe + B_lam(lam_arr[1], T, C)) * y_arr[1]**A_V_fit,\n",
    "        (f_H + B_lam(lam_arr[2], T, C)) * y_arr[2]**A_V_fit,\n",
    "        (f_Fe + B_lam(lam_arr[3], T, C)) * y_arr[3]**A_V_fit ])\n",
    "\n",
    "#for method newton-krylov redefining function to setup a system of equations equal to 0 \n",
    "def scatt_equ_solver(input_arr):\n",
    "    C, A_V_fit, f_H, f_Fe = input_arr\n",
    "\n",
    "    equ_sys = pix_flux - np.array([\n",
    "        (R_H * f_H + B_lam([lam_arr[0], bw_arr[0]], T, C)) * y_arr[0]**A_V_fit, \n",
    "        (R_Fe * f_Fe + B_lam([lam_arr[1], bw_arr[1]], T, C)) * y_arr[1]**A_V_fit,\n",
    "        (f_H + B_lam([lam_arr[2], bw_arr[2]], T, C)) * y_arr[2]**A_V_fit,\n",
    "        (f_Fe + B_lam([lam_arr[3], bw_arr[3]], T, C)) * y_arr[3]**A_V_fit \n",
    "        ])\n",
    "    return equ_sys\n",
    "\n",
    "\n",
    "#attempting many solvers\n",
    "from scipy.optimize import newton_krylov\n",
    "from scipy.optimize import curve_fit\n",
    "xin = [5e3, 1e-23]\n",
    "\n",
    "#different initial guesses\n",
    "i_num = 500\n",
    "xin_root = [5.63120728e-28, 1., 1e-18, 1e-17]\n",
    "xin_nk = np.array([5.63120728e-25, 7., 1e-18, 1e-17])\n",
    "xin1 = [1e-28, 10, 1e-18, 1e-17]\n",
    "xin2 = [5e-25, 7, 1e-18, 1e-17]\n",
    "# xin2 = [0. ,0., 0., 0.]\n",
    "\n",
    "\n",
    "\n",
    "#array of zeros to contain fit data...\n",
    "fit_arr2 = [[] for x in range(cont_flux2[0].shape[0] * cont_flux2[0].shape[1])]\n",
    "count = 0 #count variable to index this list\n",
    "\n",
    "\n",
    "#trying Dan's method of setting temperature...\n",
    "T = 4500.\n",
    "\n",
    "#beginning loop...\n",
    "for i in range(cont_flux2[0].shape[0]):\n",
    "    for j in range(cont_flux2[0].shape[1]):\n",
    "        pix_flux = np.array([cont_flux2[0][i, j], cont_flux2[1][i, j], cont_flux2[2][i, j], cont_flux2[3][i, j]])\n",
    "#         sigma_arr = [cont_flux[0][i, j]/1e5, cont_flux[1][i, j]/1e5, cont_flux[2][i, j]/1e5, cont_flux[3][i, j]/1e5]\n",
    "        \n",
    "        #trying to get fit\n",
    "        try:\n",
    "#           #now setting up for curve_fit\n",
    "            popt, pcov = curve_fit(scatt_func, lam_arr, pix_flux, p0=xin2)#, bounds=([0,0,0,0], [np.inf,np.inf,np.inf,np.inf])) #solving!\n",
    "            C_fit, A_V_fit, f_H_fit, f_Fe_fit = popt\n",
    "            #chi^2 test...against curve_fit\n",
    "            obs_intens = pix_flux\n",
    "            theory_intens = scatt_func(lam_arr, C_fit, A_V_fit, f_H_fit, f_Fe_fit)\n",
    "            n_obs = len(obs_intens)\n",
    "            chi2 = np.sum((obs_intens - theory_intens)**2.)\n",
    "            print('non-linear attempt, curve fit: ', [ C_fit, A_V_fit, f_H_fit, f_Fe_fit])\n",
    "            print('fit intensities, curve fit: ', scatt_func(lam_arr,  C_fit, A_V_fit, f_H_fit, f_Fe_fit))\n",
    "            print('sum(squared diffs, curve fit): ', chi2)\n",
    "\n",
    "            #saving results\n",
    "            fit_arr2[count] = [i, j, chi2, theory_intens, T, C_fit, A_V_fit, f_H_fit, f_Fe_fit]\n",
    "\n",
    "\n",
    "        #should try newton krylov as backup...\n",
    "        except Exception as e: \n",
    "            try:\n",
    "                solved = newton_krylov(scatt_equ_solver, xin_nk)#, f_tol=1e-14, method='gmres') #non-lin solver. ftol 1E-8ish with gmres\n",
    "                print('non-linear attempt, NK: ', solved)\n",
    "                #separating fit into diff variables...calculating a sum of squared diffs\n",
    "                C_nk, A_V_fitnk, f_H_nk, f_Fe_nk = solved\n",
    "                print('fit intensities, NK: ', scatt_func(lam_arr, C_nk, A_V_fitnk, f_H_nk, f_Fe_nk))\n",
    "                #calculating sum of squared diffs...against newton-krylov\n",
    "                obs_intens = pix_flux\n",
    "                theory_intens = scatt_func(lam_arr, C_nk, A_V_fitnk, f_H_nk, f_Fe_nk)\n",
    "                chi2 = np.sum((pix_flux - theory_intens)**2.)\n",
    "                print('sum(squared diffs, NK): ', chi2)\n",
    "\n",
    "                #saving results\n",
    "                fit_arr2[count] = [i, j, chi2, theory_intens, T, C_nk, A_V_fitnk, f_H_nk, f_Fe_nk]\n",
    "                \n",
    "            except Exception as e2:\n",
    "                print('type is:', e2.__class__.__name__)\n",
    "                fit_arr2[count] = [i, j, -1, [-1, -1, -1, -1], -1, -1, -1, -1, -1]\n",
    "            \n",
    "\n",
    "        \n",
    "\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting solution found for hh7 region pixels\n",
    "\n",
    "#plotting cutouts of actual data\n",
    "implot(datacut1, wcscut1, False, np.mean(datacut1)/1e1, np.min(datacut1))\n",
    "plt.title('H Alpha')\n",
    "implot(datacut2, wcscut2, False, np.mean(datacut2)/1e1, np.min(datacut2))\n",
    "plt.title('1.26 microns')\n",
    "implot(datacut3, wcscut3, False, np.mean(datacut3)/1e1, np.min(datacut3))\n",
    "plt.title('1.28 microns')\n",
    "implot(datacut4, wcscut4, False, np.mean(datacut4)/1e1, np.min(datacut4))\n",
    "plt.title('1.64 microns')\n",
    "\n",
    "\n",
    "#planning to save file data...\n",
    "#format: fit_arr[count] = [i, j, chi2, theory_intens, T, C_fit, A_V_fit, f_H_fit, f_Fe_fit]\n",
    "#header=[\"i\", \"j\", \"sumsq\", \"Intensity(W/m^3/sr)\" ,\"Temp(K)\", \"C\", \"A_V\", \"f_H\", \"f_Fe\"]\n",
    "# my_data = np.savetxt('fitting_box16_bad.txt', fit_arr, delimiter=',')\n",
    "\n",
    "#setting up array of model fluxes\n",
    "# model_arr_lam1 = np.zeros_like(cont_flux2[0])\n",
    "# model_arr_lam2 = np.zeros_like(cont_flux2[0])\n",
    "# model_arr_lam3 = np.zeros_like(cont_flux2[0])\n",
    "# model_arr_lam4 = np.zeros_like(cont_flux2[0])\n",
    "f_H_arr = np.zeros_like(cont_flux2[0])\n",
    "f_Fe_arr = np.zeros_like(cont_flux2[0])\n",
    "C_arr = np.zeros_like(cont_flux2[0])\n",
    "A_V_arr = np.zeros_like(cont_flux2[0])\n",
    "\n",
    "\n",
    "ind = 3 # used for picking type of image to plot\n",
    "#reorganizing data in 2d array to be plotted\n",
    "\n",
    "for line in fit_arr2:\n",
    "\n",
    "    #indices\n",
    "    i = line[0]\n",
    "    j = line[1]\n",
    "\n",
    "    #storing model intensity data\n",
    "#     try:\n",
    "#     model_arr_lam1[i][j] = line[ind][0]\n",
    "#     model_arr_lam2[i][j] = line[ind][1]\n",
    "#     model_arr_lam3[i][j] = line[ind][2]\n",
    "#     model_arr_lam4[i][j] = line[ind][3]\n",
    "\n",
    "    C_arr[i][j] = line[-4]\n",
    "    A_V_arr[i][j] = line[-3]\n",
    "    f_H_arr[i][j] = line[-2]\n",
    "    f_Fe_arr[i][j] = line[-1]\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "#plotting\n",
    "# implot(model_arr_lam1, w, True, np.max(model_arr_lam1)/5.) \n",
    "# implot(model_arr_lam2, w, True, np.max(model_arr_lam1)/5.) \n",
    "# implot(model_arr_lam3, w, True, np.max(model_arr_lam1)/5.) \n",
    "# implot(model_arr_lam4, w, True, np.max(model_arr_lam1)/40.) \n",
    "\n",
    "# print(np.max(C_arr), np.max(A_V_arr), np.max(f_H_arr), np.max(f_Fe_arr))\n",
    "# print(C_arr)\n",
    "# print(A_V_arr)\n",
    "# # implot(C_arr, w, True, np.max(C_arr)/1e10) #for \"perfect fit\" curve_fit\n",
    "# implot(C_arr, w, True, np.max(C_arr)/4e4) #for positive valued curve_fit\n",
    "# plt.title('C')\n",
    "# # implot(A_V_arr, w, True, np.max(A_V_arr)) #for \"perfect fit\" curve_fit\n",
    "# implot(A_V_arr, w, True, np.max(A_V_arr)/2e2) #for positive valued curve_fit\n",
    "# plt.title('A_V')\n",
    "# # implot(f_H_arr, w, True, np.max(f_H_arr)/1e9) #for \"perfect fit\" curve_fit\n",
    "# implot(f_H_arr, w, True, np.max(f_H_arr)/6e3) #for positive valued curve_fit\n",
    "# plt.title('f_H')\n",
    "# # implot(f_Fe_arr, w, True, np.max(f_Fe_arr)/5e6) #for \"perfect fit\" curve_fit\n",
    "# implot(f_Fe_arr, w, True, np.max(f_Fe_arr)/4e3) #for positive valued curve_fit\n",
    "# plt.title('f_Fe')\n",
    "# # implot(model_arr_lam3, w, True, np.max(model_arr_lam1)/5.) \n",
    "# # implot(model_arr_lam4, w, True, np.max(model_arr_lam1)/40.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting cutouts of regions of the image for reference\n",
    "\n",
    "#the entire large region coordinates\n",
    "cen_x = 690 # 580\n",
    "cen_y = 440 # 370\n",
    "del_x = 400 # 55\n",
    "del_y = 300 #100\n",
    "\n",
    "#trying to cut out the same region in all 4 images\n",
    "# #HH9? The arcy feature thing\n",
    "cutout1 = Cutout2D(array2, (cen_x, cen_y), (del_y, del_x), wcs = w.celestial)\n",
    "datacut1 = cutout1.data\n",
    "wcscut1 = cutout1.wcs \n",
    "\n",
    "cutout2 = Cutout2D(hdu1_conv_scaled, (cen_x, cen_y), (del_y, del_x), wcs = w.celestial)\n",
    "datacut2 = cutout2.data\n",
    "wcscut2 = cutout2.wcs \n",
    "\n",
    "cutout3 = Cutout2D(array, (cen_x, cen_y), (del_y, del_x), wcs = w.celestial)\n",
    "datacut3 = cutout3.data\n",
    "wcscut3 = cutout3.wcs \n",
    "\n",
    "cutout4 = Cutout2D(array3, (cen_x, cen_y), (del_y, del_x), wcs = w.celestial)\n",
    "datacut4 = cutout4.data\n",
    "wcscut4 = cutout4.wcs \n",
    "\n",
    "#plotting cutouts for all wavelengths\n",
    "msize = 8\n",
    "implot(array2, w, True, np.mean(array2)) \n",
    "plt.scatter([690], [440], color = 'violet', s=msize)\n",
    "# plt.scatter([690+1], [440+1], color = 'violet', s=msize)\n",
    "# plt.scatter([690-1], [440+1], color = 'violet', s=msize)\n",
    "plt.scatter([690+25-10], [440+35+10], color = 'violet', s=msize)\n",
    "plt.scatter([690-50], [440-30], color = 'violet', s=msize)\n",
    "plt.scatter([690+25], [440+60], color = 'violet', s=msize)\n",
    "plt.scatter([690-25], [440+75], color = 'violet', s=msize)\n",
    "\n",
    "implot(hdu1_conv_scaled, w, True, np.mean(datacut2)) \n",
    "plt.scatter([690], [440], color = 'violet', s=msize)\n",
    "# plt.scatter([690+1], [440+1], color = 'violet', s=msize)\n",
    "# plt.scatter([690-1], [440+1], color = 'violet', s=msize)\n",
    "plt.scatter([690+25-10], [440+35+10], color = 'violet', s=msize)\n",
    "plt.scatter([690-50], [440-30], color = 'violet', s=msize)\n",
    "plt.scatter([690+25], [440+60], color = 'violet', s=msize)\n",
    "plt.scatter([690-25], [440+75], color = 'violet', s=msize)\n",
    "\n",
    "implot(array, w, True, np.mean(datacut3)) \n",
    "plt.scatter([690], [440], color = 'violet', s=msize)\n",
    "# plt.scatter([690+1], [440+1], color = 'violet', s=msize)\n",
    "# plt.scatter([690-1], [440+1], color = 'violet', s=msize)\n",
    "plt.scatter([690+25-10], [440+35+10], color = 'violet', s=msize)\n",
    "plt.scatter([690-50], [440-30], color = 'violet', s=msize)\n",
    "plt.scatter([690+25], [440+60], color = 'violet', s=msize)\n",
    "plt.scatter([690-25], [440+75], color = 'violet', s=msize)\n",
    "\n",
    "implot(array3, w, True, np.mean(datacut4)) \n",
    "plt.scatter([690], [440], color = 'violet', s=msize)\n",
    "# plt.scatter([690+1], [440+1], color = 'violet', s=msize)\n",
    "# plt.scatter([690-1], [440+1], color = 'violet', s=msize)\n",
    "plt.scatter([690+25-10], [440+35+10], color = 'violet', s=msize)\n",
    "plt.scatter([690-50], [440-30], color = 'violet', s=msize)\n",
    "plt.scatter([690+25], [440+60], color = 'violet', s=msize)\n",
    "plt.scatter([690-25], [440+75], color = 'violet', s=msize)\n",
    "plt.scatter([690+4], [440+4], color = 'violet', s=msize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
